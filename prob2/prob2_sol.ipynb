{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Policy Gradients\n",
    "\n",
    "Authors: Sean Lin, Jaiveer Singh, Ethan Mehta\n",
    "\n",
    "Estimated Time: 3 hrs.\n",
    "\n",
    "References: \n",
    "\n",
    "- OpenAI Spinning Up (https://spinningup.openai.com/en/latest/index.html)\n",
    "<br> OpenAI's open source resource on reinforcement learning, Spinning Up, provides utils files and skeleton code for vanilla policy gradients that we built upon for this assignment\n",
    "\n",
    "- EECS 16A Segway Tours Problem: https://eecs16a.org/homework/prob4.pdf\n",
    "\n",
    "- Vanilla Policy Gradients: https://medium.com/@aniket.tcdav/vanilla-policy-gradient-with-tensorflow-2-9855df271472, https://www.janisklaise.com/post/rl-policy-gradients/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Recall the classic EECS 16AB self-balancing segway problem. The segway problem is used as a means to develop fundamental understanding of control theory and linear algebra. Interestingly, we can use reinforcement learning methods to teach a segway how to self-balance! In the previous walkthrough assignment, you were introduced to the fundamental concepts of reinforcement of learning: actions, states, policies, and rewards. This assignment will use the segway problem as a means to introduce students to reinforcement learning, policy gradients as a means of optimizing policies, and deep RL.\n",
    "\n",
    "<img src=\"images/segway.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We have prepared a conda environment for you to work on this assignment, since this assignment uses packages such as tensorflow, numpy, and OpenAI gym that may cause problems if the versions are incompatible and different. Follow the following steps to set up the environment:\n",
    "\n",
    "1) In this problem's, you should see an environment.yml file.\n",
    "<br> 2) Create a new conda environment named spinningup by running `conda env create --file environment.yaml`\n",
    "<br> 3) Run `conda activate spinningup` to activate the environment\n",
    "<br> 4) Run `python -m ipykernel install --user --name=spinningup` to export this environment into an iPython notebook kernel so that we can use it in this notebook.\n",
    "<br> 5) Restart the jupyter notebook. In the menu, go to `Kernel -> Change Kernel`. You should see an environment named `spinningup` among the list of kernels. Switch your kernel to `spinningup`, and now you are all set!\n",
    "<br>\n",
    "<img src='images/kernel_change.png' width=\"909\" height=\"500\">\n",
    "</br>\n",
    "<br> 6) Run the imports below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/seanlin/Desktop/MehtaKnights-189/prob2/utils/mpi_tf.py:29: The name tf.train.AdamOptimizer is deprecated. Please use tf.compat.v1.train.AdamOptimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import gym\n",
    "from gym.wrappers.monitor import Monitor, load_results\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import core\n",
    "import vpg\n",
    "from utils.logx import EpochLogger\n",
    "from utils.mpi_tf import MpiAdamOptimizer, sync_all_params\n",
    "from utils.mpi_tools import mpi_fork, mpi_avg, proc_id, mpi_statistics_scalar, num_procs\n",
    "from utils.run_utils import setup_logger_kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Note:</b> Because machine learning, and specifically deep reinforcement learning, is still a relatively nascent field, many machine-learning libraries are fragile and require dependencies that may easily become deprecated (i.e. tensorflow 1.15 vs. tensorflow 2.0). To reproduce machine learning experiments and projects, it is paramount that one knows how to freeze and export an environment for later usage as we did for you in this assignment. We recommend that all students taking EECS 16ML be well-versed in this practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Segway to Stand Upright\n",
    "\n",
    "In the segway problem, the segway can move anywhere on the line, and lean in any way. Therefore, we can define the state of the world as the following: \n",
    "$$[\\text{position of cart}, \\text{velocity of cart}, \\text{angle of pole}, \\text{rotation rate of pole}]$$\n",
    "\n",
    "The actions that the segway can take to change its state are to 1) lean left and 2) lean right.\n",
    "We can imagine the reward as the amount of time that the segway stays upright without falling down. Now, we just need to determine a policy such that the segway can take the optimal actions, given the state, to maximize the reward.\n",
    "\n",
    "As always, let's start with a simple example. We will program an agent that uses a logistic policy to linearly classify our decision to either lean left or right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Implement the gradient ascent step for a basic policy\n",
    "\n",
    "Below, we define the `LogisticPolicy` class. Most of the code is already implemented for you, including the code to calculate the reward and the gradient of the log likelihood. Your task is to implement the gradient ascent step in the `update` function of the class. Recall that the gradient ascent step is defined as the following:\n",
    "\n",
    "$$\\theta_{t+1} = \\theta_t + \\alpha *(E_\\theta[\\sum_{t=1}^T \\nabla_\\theta \\log P(s_{t+1} | s_t, a_t) R(\\tau)])$$\n",
    "\n",
    "The reward is calculated in `discount_rewards` and the gradient of the log likelihood is calculated in `grad_log_p`. Fill in the code for `update` to complete gradient ascent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticPolicy:\n",
    "\n",
    "    def __init__(self, theta, alpha, gamma):\n",
    "        # Initialize paramters θ, learning rate α and discount factor γ\n",
    "\n",
    "        self.theta = theta\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "\n",
    "    def logistic(self, y):\n",
    "        # definition of logistic function\n",
    "\n",
    "        return 1/(1 + np.exp(-y))\n",
    "\n",
    "    def probs(self, x):\n",
    "        # returns probabilities of two actions\n",
    "\n",
    "        y = x @ self.theta\n",
    "        prob0 = self.logistic(y)\n",
    "\n",
    "        return np.array([prob0, 1-prob0])\n",
    "\n",
    "    def get_action(self, x):\n",
    "        # sample an action in proportion to probabilities\n",
    "\n",
    "        probs = self.probs(x)\n",
    "        action = np.random.choice([0, 1], p=probs)\n",
    "\n",
    "        return action, probs[action]\n",
    "\n",
    "    def grad_log_p(self, x):\n",
    "        # calculate grad-log-probs\n",
    "\n",
    "        y = x @ self.theta\n",
    "        grad_log_p0 = x - x*self.logistic(y)\n",
    "        grad_log_p1 = - x*self.logistic(y)\n",
    "\n",
    "        return grad_log_p0, grad_log_p1\n",
    "\n",
    "    def discount_rewards(self, rewards):\n",
    "        # calculate discounted rewards\n",
    "\n",
    "        discounted_rewards = np.zeros(len(rewards))\n",
    "        cumulative_rewards = 0\n",
    "        for i in reversed(range(0, len(rewards))):\n",
    "            cumulative_rewards = cumulative_rewards * self.gamma + rewards[i]\n",
    "            discounted_rewards[i] = cumulative_rewards\n",
    "\n",
    "        return discounted_rewards\n",
    "\n",
    "    def update(self, rewards, obs, actions):\n",
    "        # calculate gradients for each action over all observations\n",
    "        grad_log_p = np.array([self.grad_log_p(ob)[action] for ob,action in zip(obs,actions)])\n",
    "\n",
    "        assert grad_log_p.shape == (len(obs), 4)\n",
    "\n",
    "        # calculate the rewards earned for a specific trajectory of actions\n",
    "        discounted_rewards = self.discount_rewards(rewards)\n",
    "        \n",
    "        ### SOLUTION ###\n",
    "        dot = grad_log_p.T @ discounted_rewards\n",
    "\n",
    "        self.theta += self.alpha*dot\n",
    "        ### END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Implement the train step of the reinforcement learning trainer\n",
    "\n",
    "Now, we will implement the model trainer, which will iterate through the data and optimize our policy. Below, we define the `RLTrainer` class. Most of the code is already implemented for you; all you have to do is fill in the code inside of the `train` loop. The loop should do three things:\n",
    "1) Run an episode (simulation) of the segway world given the current policy<br>\n",
    "2) Append the total reward computed from the episode to the list `episode_rewards` for future graphical analysis<br>\n",
    "3) Update the model policy given the rewards, observations, and actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RLTrainer:\n",
    "    \n",
    "    def __init__(self, policy):\n",
    "        self.policy = policy\n",
    "        self.env = gym.make('CartPole-v0')\n",
    "        \n",
    "    def run_episode(self, model_policy, render=True):\n",
    "\n",
    "        observation = self.env.reset()\n",
    "        totalreward = 0\n",
    "\n",
    "        observations = []\n",
    "        actions = []\n",
    "        rewards = []\n",
    "        probs = []\n",
    "\n",
    "        done = False\n",
    "\n",
    "        while not done:\n",
    "            if render:\n",
    "                self.env.render()\n",
    "\n",
    "            observations.append(observation)\n",
    "\n",
    "            action, prob = model_policy.get_action(observation)\n",
    "            observation, reward, done, info = self.env.step(action)\n",
    "\n",
    "            totalreward += reward\n",
    "            rewards.append(reward)\n",
    "            actions.append(action)\n",
    "            probs.append(prob)\n",
    "\n",
    "        return totalreward, np.array(rewards), np.array(observations), np.array(actions), np.array(probs)\n",
    "    \n",
    "    def train(self, theta, alpha, gamma, MAX_EPISODES=1000, seed=np.random.seed(0)):\n",
    "        # Initialize variables\n",
    "        episode_rewards = []\n",
    "        model_policy = self.policy(theta, alpha, gamma)\n",
    "\n",
    "        # train until MAX_EPISODES\n",
    "        for i in range(MAX_EPISODES):\n",
    "            \n",
    "            ### SOLUTION ###\n",
    "            total_reward, rewards, observations, actions, probs = self.run_episode(model_policy)\n",
    "            episode_rewards.append(total_reward)\n",
    "            model_policy.update(rewards, observations, actions)\n",
    "            ### END ###\n",
    "            \n",
    "            print(\"EP: \" + str(i) + \" Score: \" + str(total_reward) + \" \",end=\"\\r\", flush=False)\n",
    "        self.env.close()\n",
    "        return episode_rewards, model_policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have implemented the model policy and trainer, run the code block below to watch our segway learn to stand upright! We train with a learning rate of 0.002, gamma of 0.99, and 300 episodes.\n",
    "\n",
    "A reward of 200 means that the segway successfully learned how to stand upright for a substantial period of time, and thus completed its challenge!\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "1) Around how many episodes does it take for the CartPole to complete the challenge?\n",
    "<br> <i> Answer: </i>\n",
    "\n",
    "\n",
    "2) What do you notice about the CartPole as it is training? Describe its improvement over time.\n",
    "<br> <i> Answer: </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/seanlin/opt/anaconda3/envs/spinningup/lib/python3.6/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP: 299 Score: 173.0 \r"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "trainer = RLTrainer(LogisticPolicy)\n",
    "\n",
    "episode_rewards, policy = trainer.train(theta=np.random.rand(4),\n",
    "                                alpha=0.002,\n",
    "                                gamma=0.99,\n",
    "                                MAX_EPISODES=300)\n",
    "plt.plot(episode_rewards)\n",
    "plt.title(\"Graph of the reward obtained at each episode\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"Reward\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Policies: Intro to Deep RL\n",
    "\n",
    "In the previous section, we used a logistic policy as a means to teach our segway to stand upright. While the segway did imporve and eventually complete the challenge, you probably noticed that its performance fluctuated: on one episode it may complete the challenge, and on the next episode it may completely fail! \n",
    "\n",
    "Perhaps we can develop a more sophisticated policy to further improve our segway's performance? This is where neural networks come in handy. Given observations as input, we can develop a classification neural network that outputs the probabilities that we pick an action. Given these probabilities, we then sample from a multinomial distribution defined by these probabilities to pick what action to take.\n",
    "\n",
    "In the case of the CartPole, we have two actions that we can take: move left or move right. After feeding our observational data into our neural network. We do some processing to obtain the probabilities of moving left ($p_l$) and right ($p_r$) respectively. Since we have two actions, we can use a $binomial(p_l)$ distribution to sample for which action to take! In the following exercises, we will implement such a categorical policy using TensorFlow.\n",
    "\n",
    "\n",
    "<img src=\"images/policy_nn.png\" width=\"576\" height=\"300\">\n",
    "\n",
    "### Task 3: Implement Multilayer Perceptron\n",
    "\n",
    "In this task, we will define a categorical policy computed via a multilayer perceptron. \n",
    "\n",
    "First, fill in the function `mlp`. `mlp` builds a multilayer perceptron. It takes in as parameter layers, which specifies the number of units per layer in the multilayer perceptron (i.e. if layers=[64,64,2], we have 2 fully connected layers of 64 units, and an output layer of 2 units). It also takes in x, the input tensor, and activation functions that are necessary for the construction of the neural network.\n",
    "\n",
    "Hint: You my find the function `tf.layers.dense` helpful.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp(x, layers=[64,64,2], activation=tf.tanh, output_activation=None):\n",
    "    \"\"\"\n",
    "    Builds a multi-layer perceptron in Tensorflow.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor.\n",
    "\n",
    "        layers: Tuple, list, or other iterable giving the number of units\n",
    "            for each layer of the MLP.\n",
    "\n",
    "        activation: Activation function for all layers except last.\n",
    "\n",
    "        output_activation: Activation function for last layer.\n",
    "\n",
    "    Returns:\n",
    "        A TF symbol for the output of an MLP that takes x as an input.\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ### SOLUTION ###\n",
    "    for layer in layers[:-1]:\n",
    "        x = tf.layers.dense(x, units=layer, activation=activation)\n",
    "    return tf.layers.dense(x, units=layers[-1], activation=output_activation)\n",
    "    ### END ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Implement Categorical Policy\n",
    "\n",
    "Now that we have a multilayer perceptron that can take in observations as input and compute the log-odds (logits) of our two actions, we want to define a categorical policy that makes use of this MLP to determine our action. Follow the following steps to implement our categorical policy:\n",
    "\n",
    "1) Call `mlp` on the appropriate arguments to obtain a tensor of logits (log-odds) for our actions. Logits are defined as follows:\n",
    "\n",
    "$$logit(p_a) = \\log{\\frac{p_a}{1-p_a}}$$\n",
    "\n",
    "where $p$ is defined as the probability of taking action $a$.\n",
    "\n",
    "2) To convert logits to probabilities, we can take a softmax of the logits. For an action a, the softmax is defined as follows: \n",
    "\n",
    "$$ Softmax(a) = \\frac{e^{l_a}}{\\sum_{a' \\in A} e^{l_a'}} $$\n",
    "\n",
    "where $l_a$ is the logit for action $a$, and $A$ is the set of all actions.\n",
    "<br>In this case, we want to take the log of the softmax because it is easier to compute gradients with log softmaxes. \n",
    "\n",
    "3) Sample from a multinomial distribution to obtain our action.\n",
    "\n",
    "<b> Hint 1: </b> Read up on the functions `tf.nn.log_softmax` and `tf.multinomial`\n",
    "<br><b> Hint 2: </b> The number of actions that we can take is represented as `action_space.n`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_categorical_policy(x, a, nn_sizes, activation, output_activation, action_space):\n",
    "    \"\"\"\n",
    "    Builds TF symbols to sample actions and compute log-probabilities of those actions.\n",
    "\n",
    "    Args:\n",
    "        x: Input tensor of states. Shape [batch, obs_dim].\n",
    "\n",
    "        a: Input tensor of actions. Shape [batch, act_dim].\n",
    "\n",
    "        nn_sizes: Sizes of the layers for action network MLP, excluding the output layer.\n",
    "\n",
    "        activation: Activation function for all layers except last.\n",
    "\n",
    "        output_activation: Activation function for last layer (action layer).\n",
    "\n",
    "        action_space: A gym.spaces object describing the action space of the\n",
    "            environment this agent will interact with.\n",
    "\n",
    "    Returns:\n",
    "        pi: A symbol for sampling stochastic actions from a multinomial distribution\n",
    "\n",
    "        logp: A symbol for computing log-likelihoods of actions from a multinomial distribution.\n",
    "\n",
    "        logp_pi: A symbol for computing log-likelihoods of actions in pi from a multinomial distribution\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    ### SOLUTION ###\n",
    "    act_dim = action_space.n\n",
    "    logits = mlp(x, list(nn_sizes)+[act_dim], activation, None)\n",
    "    logp_all = tf.nn.log_softmax(logits)\n",
    "    sample = tf.multinomial(logits,1)\n",
    "    ### END ###\n",
    "    pi = tf.squeeze(sample, axis=1)\n",
    "    logp = tf.reduce_sum(tf.one_hot(a, depth=act_dim) * logp_all, axis=1)\n",
    "    logp_pi = tf.reduce_sum(tf.one_hot(pi, depth=act_dim) * logp_all, axis=1)\n",
    "    return pi, logp, logp_pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5: Run the Segway Experiment again!\n",
    "\n",
    "Below is the starter code to run the CartPole experiment with our more powerful model using a neural network policy. We use an algorithm called Vanilla Policy Gradient (VPG) that takes in your categorical policy and trains on the segway problem. All that is left to do is initialize some of the experiment parameters. We want our categorical policy to be a 3 layer neural network. The first two layers consist of 64 units. Given this information, fill in `nn_units` and `depth` accordingly. Remember that the last layer of the neural network is not defined here, but in the `mlp_categorical_policy` function that you wrote above.\n",
    "\n",
    "Train for 100 epochs and 4000 steps per epoch. The model should take roughly 20-30 min. to train. As you train your RL model, you will be able to see the cartpole training. Pay attention to the metric AverageEpRet––this is the average reward that your model achieved in the epoch. If your code was implemented correctly, AverageEpRet should achieve scores of roughly 200 or higher in the last 10 epochs.\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "1) What is the AverageEpRet of your model in the final 10 epochs? \n",
    "<br> <i> Answer: </i>\n",
    "\n",
    "\n",
    "2) What do you notice about the CartPole as it is training? Describe its improvement over time.\n",
    "<br> <i> Answer: </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Log dir /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0 already exists! Storing info there anyway.\n",
      "\u001b[32;1mLogging data to /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/progress.txt\u001b[0m\n",
      "\u001b[36;1mSaving config:\n",
      "\u001b[0m\n",
      "{\n",
      "    \"ac_kwargs\":\t{\n",
      "        \"nn_sizes\":\t[\n",
      "            64,\n",
      "            64\n",
      "        ],\n",
      "        \"policy\":\t\"mlp_categorical_policy\"\n",
      "    },\n",
      "    \"actor_critic\":\t\"mlp_actor_critic\",\n",
      "    \"env_fn\":\t\"<function <lambda> at 0x142d6f950>\",\n",
      "    \"epochs\":\t100,\n",
      "    \"exp_name\":\t\"vpg\",\n",
      "    \"gamma\":\t0.99,\n",
      "    \"lam\":\t0.97,\n",
      "    \"logger\":\t{\n",
      "        \"<utils.logx.EpochLogger object at 0x142d78fd0>\":\t{\n",
      "            \"epoch_dict\":\t{},\n",
      "            \"exp_name\":\t\"vpg\",\n",
      "            \"first_row\":\ttrue,\n",
      "            \"log_current_row\":\t{},\n",
      "            \"log_headers\":\t[],\n",
      "            \"output_dir\":\t\"/Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0\",\n",
      "            \"output_file\":\t{\n",
      "                \"<_io.TextIOWrapper name='/Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/progress.txt' mode='w' encoding='UTF-8'>\":\t{\n",
      "                    \"mode\":\t\"w\"\n",
      "                }\n",
      "            }\n",
      "        }\n",
      "    },\n",
      "    \"logger_kwargs\":\t{\n",
      "        \"exp_name\":\t\"vpg\",\n",
      "        \"output_dir\":\t\"/Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0\"\n",
      "    },\n",
      "    \"max_ep_len\":\t1000,\n",
      "    \"pi_lr\":\t0.0003,\n",
      "    \"save_freq\":\t10,\n",
      "    \"seed\":\t0,\n",
      "    \"steps_per_epoch\":\t4000,\n",
      "    \"train_v_iters\":\t80,\n",
      "    \"vf_lr\":\t0.001\n",
      "}\n",
      "WARNING:tensorflow:From /Users/seanlin/Desktop/MehtaKnights-189/prob2/vpg.py:155: The name tf.set_random_seed is deprecated. Please use tf.compat.v1.set_random_seed instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/seanlin/Desktop/MehtaKnights-189/prob2/core.py:14: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/seanlin/Desktop/MehtaKnights-189/prob2/core.py:102: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-5-069ae3840a61>:22: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n",
      "WARNING:tensorflow:From /Users/seanlin/opt/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow_core/python/layers/core.py:187: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-a50e8c69b083>:32: multinomial (from tensorflow.python.ops.random_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.random.categorical` instead.\n",
      "WARNING:tensorflow:From /Users/seanlin/Desktop/MehtaKnights-189/prob2/core.py:35: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "\u001b[32;1m\n",
      "Number of parameters: \t pi: 4610, \t v: 4545\n",
      "\u001b[0m\n",
      "WARNING:tensorflow:From /Users/seanlin/Desktop/MehtaKnights-189/prob2/utils/mpi_tf.py:63: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "WARNING:tensorflow:From /Users/seanlin/Desktop/MehtaKnights-189/prob2/utils/mpi_tf.py:14: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/seanlin/opt/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/seanlin/Desktop/MehtaKnights-189/prob2/vpg.py:198: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/seanlin/Desktop/MehtaKnights-189/prob2/vpg.py:199: The name tf.global_variables_initializer is deprecated. Please use tf.compat.v1.global_variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/seanlin/Desktop/MehtaKnights-189/prob2/utils/mpi_tf.py:26: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Warning: trajectory cut off by epoch at 1 steps.\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "WARNING:tensorflow:From /Users/seanlin/Desktop/MehtaKnights-189/prob2/utils/logx.py:227: simple_save (from tensorflow.python.saved_model.simple_save) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.simple_save.\n",
      "WARNING:tensorflow:From /Users/seanlin/opt/anaconda3/envs/spinningup/lib/python3.6/site-packages/tensorflow_core/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/tf1_save/saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |               0 |\n",
      "|      AverageEpRet |            28.6 |\n",
      "|          StdEpRet |            16.2 |\n",
      "|          MaxEpRet |              90 |\n",
      "|          MinEpRet |              11 |\n",
      "|             EpLen |            28.6 |\n",
      "|      AverageVVals |        -0.00587 |\n",
      "|          StdVVals |           0.179 |\n",
      "|          MaxVVals |           0.807 |\n",
      "|          MinVVals |          -0.698 |\n",
      "| TotalEnvInteracts |           4e+03 |\n",
      "|            LossPi |         -0.0121 |\n",
      "|             LossV |             424 |\n",
      "|       DeltaLossPi |        -0.00259 |\n",
      "|        DeltaLossV |            -245 |\n",
      "|           Entropy |           0.684 |\n",
      "|                KL |        0.000211 |\n",
      "|              Time |            68.5 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 5 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               1 |\n",
      "|      AverageEpRet |            27.7 |\n",
      "|          StdEpRet |            15.8 |\n",
      "|          MaxEpRet |             108 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |            27.7 |\n",
      "|      AverageVVals |            10.7 |\n",
      "|          StdVVals |           0.507 |\n",
      "|          MaxVVals |            11.9 |\n",
      "|          MinVVals |            7.27 |\n",
      "| TotalEnvInteracts |           8e+03 |\n",
      "|            LossPi |         -0.0155 |\n",
      "|             LossV |             174 |\n",
      "|       DeltaLossPi |        -0.00244 |\n",
      "|        DeltaLossV |           -42.3 |\n",
      "|           Entropy |           0.685 |\n",
      "|                KL |        0.000213 |\n",
      "|              Time |             118 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 24 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               2 |\n",
      "|      AverageEpRet |            27.8 |\n",
      "|          StdEpRet |            16.6 |\n",
      "|          MaxEpRet |              94 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |            27.8 |\n",
      "|      AverageVVals |            16.3 |\n",
      "|          StdVVals |            3.67 |\n",
      "|          MaxVVals |            20.2 |\n",
      "|          MinVVals |           -5.88 |\n",
      "| TotalEnvInteracts |         1.2e+04 |\n",
      "|            LossPi |          -0.021 |\n",
      "|             LossV |             149 |\n",
      "|       DeltaLossPi |        -0.00296 |\n",
      "|        DeltaLossV |           -12.7 |\n",
      "|           Entropy |           0.686 |\n",
      "|                KL |        0.000723 |\n",
      "|              Time |             127 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 20 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               3 |\n",
      "|      AverageEpRet |            29.9 |\n",
      "|          StdEpRet |            18.6 |\n",
      "|          MaxEpRet |             117 |\n",
      "|          MinEpRet |              11 |\n",
      "|             EpLen |            29.9 |\n",
      "|      AverageVVals |            16.5 |\n",
      "|          StdVVals |            2.54 |\n",
      "|          MaxVVals |            19.7 |\n",
      "|          MinVVals |           0.422 |\n",
      "| TotalEnvInteracts |         1.6e+04 |\n",
      "|            LossPi |         -0.0194 |\n",
      "|             LossV |             163 |\n",
      "|       DeltaLossPi |        -0.00262 |\n",
      "|        DeltaLossV |           -16.6 |\n",
      "|           Entropy |           0.681 |\n",
      "|                KL |        0.000152 |\n",
      "|              Time |             135 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 1 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               4 |\n",
      "|      AverageEpRet |            32.2 |\n",
      "|          StdEpRet |            17.3 |\n",
      "|          MaxEpRet |              87 |\n",
      "|          MinEpRet |               8 |\n",
      "|             EpLen |            32.2 |\n",
      "|      AverageVVals |            17.5 |\n",
      "|          StdVVals |            4.68 |\n",
      "|          MaxVVals |            22.5 |\n",
      "|          MinVVals |           -4.31 |\n",
      "| TotalEnvInteracts |           2e+04 |\n",
      "|            LossPi |         -0.0256 |\n",
      "|             LossV |             120 |\n",
      "|       DeltaLossPi |        -0.00284 |\n",
      "|        DeltaLossV |           -7.17 |\n",
      "|           Entropy |           0.677 |\n",
      "|                KL |        0.000112 |\n",
      "|              Time |             144 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 10 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               5 |\n",
      "|      AverageEpRet |            34.7 |\n",
      "|          StdEpRet |            19.4 |\n",
      "|          MaxEpRet |             119 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |            34.7 |\n",
      "|      AverageVVals |            18.2 |\n",
      "|          StdVVals |            5.08 |\n",
      "|          MaxVVals |            24.3 |\n",
      "|          MinVVals |           -3.15 |\n",
      "| TotalEnvInteracts |         2.4e+04 |\n",
      "|            LossPi |         -0.0321 |\n",
      "|             LossV |             152 |\n",
      "|       DeltaLossPi |        -0.00297 |\n",
      "|        DeltaLossV |           -16.4 |\n",
      "|           Entropy |           0.677 |\n",
      "|                KL |        7.46e-05 |\n",
      "|              Time |             152 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 48 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               6 |\n",
      "|      AverageEpRet |            34.4 |\n",
      "|          StdEpRet |            18.4 |\n",
      "|          MaxEpRet |              92 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |            34.4 |\n",
      "|      AverageVVals |            19.6 |\n",
      "|          StdVVals |            5.63 |\n",
      "|          MaxVVals |            25.4 |\n",
      "|          MinVVals |            -3.3 |\n",
      "| TotalEnvInteracts |         2.8e+04 |\n",
      "|            LossPi |         -0.0357 |\n",
      "|             LossV |             122 |\n",
      "|       DeltaLossPi |        -0.00295 |\n",
      "|        DeltaLossV |           -9.69 |\n",
      "|           Entropy |           0.677 |\n",
      "|                KL |        0.000167 |\n",
      "|              Time |             164 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 17 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               7 |\n",
      "|      AverageEpRet |              34 |\n",
      "|          StdEpRet |            21.1 |\n",
      "|          MaxEpRet |             124 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |              34 |\n",
      "|      AverageVVals |            18.9 |\n",
      "|          StdVVals |            6.82 |\n",
      "|          MaxVVals |            25.7 |\n",
      "|          MinVVals |           -6.13 |\n",
      "| TotalEnvInteracts |         3.2e+04 |\n",
      "|            LossPi |         -0.0399 |\n",
      "|             LossV |             161 |\n",
      "|       DeltaLossPi |        -0.00307 |\n",
      "|        DeltaLossV |           -8.62 |\n",
      "|           Entropy |           0.677 |\n",
      "|                KL |        0.000462 |\n",
      "|              Time |             180 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 6 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               8 |\n",
      "|      AverageEpRet |            38.8 |\n",
      "|          StdEpRet |            23.7 |\n",
      "|          MaxEpRet |             145 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |            38.8 |\n",
      "|      AverageVVals |            20.7 |\n",
      "|          StdVVals |            6.82 |\n",
      "|          MaxVVals |              28 |\n",
      "|          MinVVals |           -1.44 |\n",
      "| TotalEnvInteracts |         3.6e+04 |\n",
      "|            LossPi |         -0.0351 |\n",
      "|             LossV |             172 |\n",
      "|       DeltaLossPi |        -0.00239 |\n",
      "|        DeltaLossV |             -15 |\n",
      "|           Entropy |           0.667 |\n",
      "|                KL |       -0.000285 |\n",
      "|              Time |             193 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 32 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |               9 |\n",
      "|      AverageEpRet |            40.5 |\n",
      "|          StdEpRet |            25.6 |\n",
      "|          MaxEpRet |             132 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |            40.5 |\n",
      "|      AverageVVals |            21.7 |\n",
      "|          StdVVals |            7.82 |\n",
      "|          MaxVVals |            29.5 |\n",
      "|          MinVVals |           -3.42 |\n",
      "| TotalEnvInteracts |           4e+04 |\n",
      "|            LossPi |         -0.0395 |\n",
      "|             LossV |             191 |\n",
      "|       DeltaLossPi |        -0.00247 |\n",
      "|        DeltaLossV |           -10.3 |\n",
      "|           Entropy |           0.668 |\n",
      "|                KL |       -0.000155 |\n",
      "|              Time |             203 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 77 steps.\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/tf1_save/saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |              10 |\n",
      "|      AverageEpRet |            38.8 |\n",
      "|          StdEpRet |            25.5 |\n",
      "|          MaxEpRet |             122 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |            38.8 |\n",
      "|      AverageVVals |            22.5 |\n",
      "|          StdVVals |            8.32 |\n",
      "|          MaxVVals |            31.9 |\n",
      "|          MinVVals |           -1.88 |\n",
      "| TotalEnvInteracts |         4.4e+04 |\n",
      "|            LossPi |         -0.0469 |\n",
      "|             LossV |             191 |\n",
      "|       DeltaLossPi |        -0.00286 |\n",
      "|        DeltaLossV |           -5.24 |\n",
      "|           Entropy |           0.668 |\n",
      "|                KL |        0.000119 |\n",
      "|              Time |             214 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 9 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              11 |\n",
      "|      AverageEpRet |            40.7 |\n",
      "|          StdEpRet |            25.7 |\n",
      "|          MaxEpRet |             122 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |            40.7 |\n",
      "|      AverageVVals |            23.3 |\n",
      "|          StdVVals |            8.21 |\n",
      "|          MaxVVals |            31.9 |\n",
      "|          MinVVals |           0.466 |\n",
      "| TotalEnvInteracts |         4.8e+04 |\n",
      "|            LossPi |         -0.0489 |\n",
      "|             LossV |             189 |\n",
      "|       DeltaLossPi |        -0.00266 |\n",
      "|        DeltaLossV |           -4.29 |\n",
      "|           Entropy |           0.664 |\n",
      "|                KL |       -3.58e-05 |\n",
      "|              Time |             226 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 28 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              12 |\n",
      "|      AverageEpRet |            38.9 |\n",
      "|          StdEpRet |            20.8 |\n",
      "|          MaxEpRet |             112 |\n",
      "|          MinEpRet |              11 |\n",
      "|             EpLen |            38.9 |\n",
      "|      AverageVVals |            23.7 |\n",
      "|          StdVVals |            8.38 |\n",
      "|          MaxVVals |            31.9 |\n",
      "|          MinVVals |           -0.15 |\n",
      "| TotalEnvInteracts |         5.2e+04 |\n",
      "|            LossPi |         -0.0515 |\n",
      "|             LossV |             134 |\n",
      "|       DeltaLossPi |        -0.00246 |\n",
      "|        DeltaLossV |           -10.1 |\n",
      "|           Entropy |           0.663 |\n",
      "|                KL |        0.000114 |\n",
      "|              Time |             241 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 82 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              13 |\n",
      "|      AverageEpRet |              40 |\n",
      "|          StdEpRet |            26.4 |\n",
      "|          MaxEpRet |             142 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |              40 |\n",
      "|      AverageVVals |            20.9 |\n",
      "|          StdVVals |            8.49 |\n",
      "|          MaxVVals |              31 |\n",
      "|          MinVVals |          -0.955 |\n",
      "| TotalEnvInteracts |         5.6e+04 |\n",
      "|            LossPi |         -0.0467 |\n",
      "|             LossV |             213 |\n",
      "|       DeltaLossPi |        -0.00236 |\n",
      "|        DeltaLossV |           -20.1 |\n",
      "|           Entropy |            0.66 |\n",
      "|                KL |       -7.51e-05 |\n",
      "|              Time |             254 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 8 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              14 |\n",
      "|      AverageEpRet |            42.5 |\n",
      "|          StdEpRet |            25.9 |\n",
      "|          MaxEpRet |             117 |\n",
      "|          MinEpRet |              11 |\n",
      "|             EpLen |            42.5 |\n",
      "|      AverageVVals |            23.8 |\n",
      "|          StdVVals |            8.67 |\n",
      "|          MaxVVals |            32.3 |\n",
      "|          MinVVals |           -1.28 |\n",
      "| TotalEnvInteracts |           6e+04 |\n",
      "|            LossPi |         -0.0493 |\n",
      "|             LossV |             185 |\n",
      "|       DeltaLossPi |        -0.00212 |\n",
      "|        DeltaLossV |           -4.49 |\n",
      "|           Entropy |           0.655 |\n",
      "|                KL |       -0.000182 |\n",
      "|              Time |             268 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 10 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              15 |\n",
      "|      AverageEpRet |            43.4 |\n",
      "|          StdEpRet |            24.4 |\n",
      "|          MaxEpRet |             110 |\n",
      "|          MinEpRet |              12 |\n",
      "|             EpLen |            43.4 |\n",
      "|      AverageVVals |            24.3 |\n",
      "|          StdVVals |            8.64 |\n",
      "|          MaxVVals |            32.4 |\n",
      "|          MinVVals |           0.768 |\n",
      "| TotalEnvInteracts |         6.4e+04 |\n",
      "|            LossPi |         -0.0511 |\n",
      "|             LossV |             156 |\n",
      "|       DeltaLossPi |        -0.00205 |\n",
      "|        DeltaLossV |           -4.24 |\n",
      "|           Entropy |           0.655 |\n",
      "|                KL |        -0.00011 |\n",
      "|              Time |             289 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 36 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              16 |\n",
      "|      AverageEpRet |            44.5 |\n",
      "|          StdEpRet |            29.6 |\n",
      "|          MaxEpRet |             163 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |            44.5 |\n",
      "|      AverageVVals |            22.4 |\n",
      "|          StdVVals |            9.35 |\n",
      "|          MaxVVals |            32.5 |\n",
      "|          MinVVals |           -2.18 |\n",
      "| TotalEnvInteracts |         6.8e+04 |\n",
      "|            LossPi |         -0.0477 |\n",
      "|             LossV |             260 |\n",
      "|       DeltaLossPi |        -0.00198 |\n",
      "|        DeltaLossV |           -28.9 |\n",
      "|           Entropy |           0.654 |\n",
      "|                KL |       -2.88e-05 |\n",
      "|              Time |             300 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 4 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              17 |\n",
      "|      AverageEpRet |            56.3 |\n",
      "|          StdEpRet |            36.9 |\n",
      "|          MaxEpRet |             195 |\n",
      "|          MinEpRet |              13 |\n",
      "|             EpLen |            56.3 |\n",
      "|      AverageVVals |            26.3 |\n",
      "|          StdVVals |            8.55 |\n",
      "|          MaxVVals |            33.9 |\n",
      "|          MinVVals |           -1.63 |\n",
      "| TotalEnvInteracts |         7.2e+04 |\n",
      "|            LossPi |         -0.0519 |\n",
      "|             LossV |             300 |\n",
      "|       DeltaLossPi |        -0.00214 |\n",
      "|        DeltaLossV |           -32.5 |\n",
      "|           Entropy |           0.653 |\n",
      "|                KL |       -4.72e-05 |\n",
      "|              Time |             310 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 7 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              18 |\n",
      "|      AverageEpRet |            51.9 |\n",
      "|          StdEpRet |            28.5 |\n",
      "|          MaxEpRet |             136 |\n",
      "|          MinEpRet |              13 |\n",
      "|             EpLen |            51.9 |\n",
      "|      AverageVVals |            29.8 |\n",
      "|          StdVVals |            10.4 |\n",
      "|          MaxVVals |            39.9 |\n",
      "|          MinVVals |           -1.65 |\n",
      "| TotalEnvInteracts |         7.6e+04 |\n",
      "|            LossPi |           -0.06 |\n",
      "|             LossV |             198 |\n",
      "|       DeltaLossPi |         -0.0023 |\n",
      "|        DeltaLossV |           -18.3 |\n",
      "|           Entropy |           0.654 |\n",
      "|                KL |        0.000207 |\n",
      "|              Time |             322 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 33 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              19 |\n",
      "|      AverageEpRet |            50.9 |\n",
      "|          StdEpRet |            36.5 |\n",
      "|          MaxEpRet |             182 |\n",
      "|          MinEpRet |              13 |\n",
      "|             EpLen |            50.9 |\n",
      "|      AverageVVals |            24.8 |\n",
      "|          StdVVals |            10.6 |\n",
      "|          MaxVVals |            37.9 |\n",
      "|          MinVVals |           0.661 |\n",
      "| TotalEnvInteracts |           8e+04 |\n",
      "|            LossPi |         -0.0473 |\n",
      "|             LossV |             365 |\n",
      "|       DeltaLossPi |        -0.00211 |\n",
      "|        DeltaLossV |           -59.2 |\n",
      "|           Entropy |           0.648 |\n",
      "|                KL |       -6.73e-05 |\n",
      "|              Time |             334 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 85 steps.\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/tf1_save/saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |              20 |\n",
      "|      AverageEpRet |            48.9 |\n",
      "|          StdEpRet |            29.4 |\n",
      "|          MaxEpRet |             179 |\n",
      "|          MinEpRet |              13 |\n",
      "|             EpLen |            48.9 |\n",
      "|      AverageVVals |            28.5 |\n",
      "|          StdVVals |            9.63 |\n",
      "|          MaxVVals |            38.1 |\n",
      "|          MinVVals |           -1.35 |\n",
      "| TotalEnvInteracts |         8.4e+04 |\n",
      "|            LossPi |          -0.058 |\n",
      "|             LossV |             264 |\n",
      "|       DeltaLossPi |        -0.00163 |\n",
      "|        DeltaLossV |             -23 |\n",
      "|           Entropy |           0.649 |\n",
      "|                KL |        9.95e-05 |\n",
      "|              Time |             346 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 55 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              21 |\n",
      "|      AverageEpRet |            54.8 |\n",
      "|          StdEpRet |            36.1 |\n",
      "|          MaxEpRet |             192 |\n",
      "|          MinEpRet |              11 |\n",
      "|             EpLen |            54.8 |\n",
      "|      AverageVVals |            27.1 |\n",
      "|          StdVVals |            8.44 |\n",
      "|          MaxVVals |            36.3 |\n",
      "|          MinVVals |          -0.797 |\n",
      "| TotalEnvInteracts |         8.8e+04 |\n",
      "|            LossPi |         -0.0503 |\n",
      "|             LossV |             302 |\n",
      "|       DeltaLossPi |        -0.00171 |\n",
      "|        DeltaLossV |           -20.7 |\n",
      "|           Entropy |           0.645 |\n",
      "|                KL |        0.000134 |\n",
      "|              Time |             357 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 31 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              22 |\n",
      "|      AverageEpRet |            56.7 |\n",
      "|          StdEpRet |            36.6 |\n",
      "|          MaxEpRet |             216 |\n",
      "|          MinEpRet |              12 |\n",
      "|             EpLen |            56.7 |\n",
      "|      AverageVVals |            29.8 |\n",
      "|          StdVVals |            9.99 |\n",
      "|          MaxVVals |            39.4 |\n",
      "|          MinVVals |           -1.66 |\n",
      "| TotalEnvInteracts |         9.2e+04 |\n",
      "|            LossPi |         -0.0599 |\n",
      "|             LossV |             271 |\n",
      "|       DeltaLossPi |         -0.0018 |\n",
      "|        DeltaLossV |           -12.1 |\n",
      "|           Entropy |           0.646 |\n",
      "|                KL |        9.09e-05 |\n",
      "|              Time |             367 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 17 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              23 |\n",
      "|      AverageEpRet |            53.1 |\n",
      "|          StdEpRet |            32.7 |\n",
      "|          MaxEpRet |             159 |\n",
      "|          MinEpRet |              11 |\n",
      "|             EpLen |            53.1 |\n",
      "|      AverageVVals |            30.3 |\n",
      "|          StdVVals |            10.7 |\n",
      "|          MaxVVals |            40.9 |\n",
      "|          MinVVals |          -0.862 |\n",
      "| TotalEnvInteracts |         9.6e+04 |\n",
      "|            LossPi |         -0.0612 |\n",
      "|             LossV |             268 |\n",
      "|       DeltaLossPi |        -0.00201 |\n",
      "|        DeltaLossV |           -28.8 |\n",
      "|           Entropy |           0.649 |\n",
      "|                KL |        0.000305 |\n",
      "|              Time |             379 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 114 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              24 |\n",
      "|      AverageEpRet |              58 |\n",
      "|          StdEpRet |            33.5 |\n",
      "|          MaxEpRet |             143 |\n",
      "|          MinEpRet |              13 |\n",
      "|             EpLen |              58 |\n",
      "|      AverageVVals |            27.9 |\n",
      "|          StdVVals |            9.75 |\n",
      "|          MaxVVals |            39.3 |\n",
      "|          MinVVals |           -1.37 |\n",
      "| TotalEnvInteracts |           1e+05 |\n",
      "|            LossPi |         -0.0648 |\n",
      "|             LossV |             243 |\n",
      "|       DeltaLossPi |        -0.00192 |\n",
      "|        DeltaLossV |             -22 |\n",
      "|           Entropy |           0.644 |\n",
      "|                KL |        0.000502 |\n",
      "|              Time |             391 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 89 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              25 |\n",
      "|      AverageEpRet |            57.5 |\n",
      "|          StdEpRet |            35.7 |\n",
      "|          MaxEpRet |             165 |\n",
      "|          MinEpRet |              12 |\n",
      "|             EpLen |            57.5 |\n",
      "|      AverageVVals |            31.5 |\n",
      "|          StdVVals |            11.1 |\n",
      "|          MaxVVals |            42.6 |\n",
      "|          MinVVals |          -0.823 |\n",
      "| TotalEnvInteracts |        1.04e+05 |\n",
      "|            LossPi |         -0.0575 |\n",
      "|             LossV |             252 |\n",
      "|       DeltaLossPi |        -0.00164 |\n",
      "|        DeltaLossV |           -19.7 |\n",
      "|           Entropy |           0.638 |\n",
      "|                KL |       -3.49e-05 |\n",
      "|              Time |             402 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 23 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              26 |\n",
      "|      AverageEpRet |            58.5 |\n",
      "|          StdEpRet |            37.9 |\n",
      "|          MaxEpRet |             185 |\n",
      "|          MinEpRet |              12 |\n",
      "|             EpLen |            58.5 |\n",
      "|      AverageVVals |            28.5 |\n",
      "|          StdVVals |              12 |\n",
      "|          MaxVVals |            42.5 |\n",
      "|          MinVVals |           -1.88 |\n",
      "| TotalEnvInteracts |        1.08e+05 |\n",
      "|            LossPi |         -0.0552 |\n",
      "|             LossV |             297 |\n",
      "|       DeltaLossPi |        -0.00152 |\n",
      "|        DeltaLossV |             -19 |\n",
      "|           Entropy |           0.638 |\n",
      "|                KL |        0.000158 |\n",
      "|              Time |             411 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 72 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              27 |\n",
      "|      AverageEpRet |            68.9 |\n",
      "|          StdEpRet |            37.2 |\n",
      "|          MaxEpRet |             153 |\n",
      "|          MinEpRet |              19 |\n",
      "|             EpLen |            68.9 |\n",
      "|      AverageVVals |            30.9 |\n",
      "|          StdVVals |            10.3 |\n",
      "|          MaxVVals |              43 |\n",
      "|          MinVVals |          -0.465 |\n",
      "| TotalEnvInteracts |        1.12e+05 |\n",
      "|            LossPi |         -0.0571 |\n",
      "|             LossV |             274 |\n",
      "|       DeltaLossPi |         -0.0014 |\n",
      "|        DeltaLossV |           -16.4 |\n",
      "|           Entropy |           0.633 |\n",
      "|                KL |       -9.25e-05 |\n",
      "|              Time |             420 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 40 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              28 |\n",
      "|      AverageEpRet |              66 |\n",
      "|          StdEpRet |            37.4 |\n",
      "|          MaxEpRet |             153 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |              66 |\n",
      "|      AverageVVals |            34.7 |\n",
      "|          StdVVals |            11.1 |\n",
      "|          MaxVVals |            45.8 |\n",
      "|          MinVVals |           0.156 |\n",
      "| TotalEnvInteracts |        1.16e+05 |\n",
      "|            LossPi |         -0.0585 |\n",
      "|             LossV |             247 |\n",
      "|       DeltaLossPi |        -0.00163 |\n",
      "|        DeltaLossV |           -13.4 |\n",
      "|           Entropy |           0.636 |\n",
      "|                KL |        0.000264 |\n",
      "|              Time |             428 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 60 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              29 |\n",
      "|      AverageEpRet |            62.5 |\n",
      "|          StdEpRet |            39.1 |\n",
      "|          MaxEpRet |             176 |\n",
      "|          MinEpRet |              11 |\n",
      "|             EpLen |            62.5 |\n",
      "|      AverageVVals |            32.9 |\n",
      "|          StdVVals |            11.8 |\n",
      "|          MaxVVals |            45.7 |\n",
      "|          MinVVals |          -0.244 |\n",
      "| TotalEnvInteracts |         1.2e+05 |\n",
      "|            LossPi |          -0.062 |\n",
      "|             LossV |             286 |\n",
      "|       DeltaLossPi |        -0.00152 |\n",
      "|        DeltaLossV |           -31.7 |\n",
      "|           Entropy |           0.634 |\n",
      "|                KL |        8.61e-05 |\n",
      "|              Time |             437 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 119 steps.\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/tf1_save/saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |              30 |\n",
      "|      AverageEpRet |            62.6 |\n",
      "|          StdEpRet |            37.8 |\n",
      "|          MaxEpRet |             197 |\n",
      "|          MinEpRet |              16 |\n",
      "|             EpLen |            62.6 |\n",
      "|      AverageVVals |            29.1 |\n",
      "|          StdVVals |              13 |\n",
      "|          MaxVVals |            45.2 |\n",
      "|          MinVVals |            1.39 |\n",
      "| TotalEnvInteracts |        1.24e+05 |\n",
      "|            LossPi |         -0.0553 |\n",
      "|             LossV |             343 |\n",
      "|       DeltaLossPi |         -0.0013 |\n",
      "|        DeltaLossV |           -59.8 |\n",
      "|           Entropy |           0.636 |\n",
      "|                KL |        0.000222 |\n",
      "|              Time |             446 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 96 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              31 |\n",
      "|      AverageEpRet |            69.7 |\n",
      "|          StdEpRet |            50.5 |\n",
      "|          MaxEpRet |             303 |\n",
      "|          MinEpRet |              17 |\n",
      "|             EpLen |            69.7 |\n",
      "|      AverageVVals |              33 |\n",
      "|          StdVVals |            9.66 |\n",
      "|          MaxVVals |              46 |\n",
      "|          MinVVals |            1.94 |\n",
      "| TotalEnvInteracts |        1.28e+05 |\n",
      "|            LossPi |         -0.0506 |\n",
      "|             LossV |             411 |\n",
      "|       DeltaLossPi |        -0.00131 |\n",
      "|        DeltaLossV |           -48.4 |\n",
      "|           Entropy |           0.629 |\n",
      "|                KL |        2.49e-06 |\n",
      "|              Time |             456 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 51 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              32 |\n",
      "|      AverageEpRet |            80.6 |\n",
      "|          StdEpRet |            52.3 |\n",
      "|          MaxEpRet |             239 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |            80.6 |\n",
      "|      AverageVVals |            34.8 |\n",
      "|          StdVVals |              12 |\n",
      "|          MaxVVals |            49.2 |\n",
      "|          MinVVals |           -1.15 |\n",
      "| TotalEnvInteracts |        1.32e+05 |\n",
      "|            LossPi |         -0.0632 |\n",
      "|             LossV |             361 |\n",
      "|       DeltaLossPi |        -0.00145 |\n",
      "|        DeltaLossV |           -67.5 |\n",
      "|           Entropy |           0.633 |\n",
      "|                KL |        0.000178 |\n",
      "|              Time |             464 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 29 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              33 |\n",
      "|      AverageEpRet |            72.2 |\n",
      "|          StdEpRet |            48.9 |\n",
      "|          MaxEpRet |             193 |\n",
      "|          MinEpRet |              15 |\n",
      "|             EpLen |            72.2 |\n",
      "|      AverageVVals |            37.5 |\n",
      "|          StdVVals |            13.6 |\n",
      "|          MaxVVals |            55.6 |\n",
      "|          MinVVals |           0.747 |\n",
      "| TotalEnvInteracts |        1.36e+05 |\n",
      "|            LossPi |         -0.0528 |\n",
      "|             LossV |             365 |\n",
      "|       DeltaLossPi |        -0.00129 |\n",
      "|        DeltaLossV |           -30.3 |\n",
      "|           Entropy |           0.629 |\n",
      "|                KL |        7.43e-05 |\n",
      "|              Time |             472 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 27 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              34 |\n",
      "|      AverageEpRet |            65.1 |\n",
      "|          StdEpRet |              39 |\n",
      "|          MaxEpRet |             171 |\n",
      "|          MinEpRet |              18 |\n",
      "|             EpLen |            65.1 |\n",
      "|      AverageVVals |            35.5 |\n",
      "|          StdVVals |            14.4 |\n",
      "|          MaxVVals |              53 |\n",
      "|          MinVVals |           0.841 |\n",
      "| TotalEnvInteracts |         1.4e+05 |\n",
      "|            LossPi |         -0.0631 |\n",
      "|             LossV |             290 |\n",
      "|       DeltaLossPi |         -0.0013 |\n",
      "|        DeltaLossV |           -35.8 |\n",
      "|           Entropy |            0.63 |\n",
      "|                KL |        0.000192 |\n",
      "|              Time |             481 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 105 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              35 |\n",
      "|      AverageEpRet |            69.6 |\n",
      "|          StdEpRet |            48.1 |\n",
      "|          MaxEpRet |             231 |\n",
      "|          MinEpRet |              12 |\n",
      "|             EpLen |            69.6 |\n",
      "|      AverageVVals |            34.8 |\n",
      "|          StdVVals |            11.5 |\n",
      "|          MaxVVals |            47.8 |\n",
      "|          MinVVals |            1.64 |\n",
      "| TotalEnvInteracts |        1.44e+05 |\n",
      "|            LossPi |         -0.0604 |\n",
      "|             LossV |             338 |\n",
      "|       DeltaLossPi |        -0.00138 |\n",
      "|        DeltaLossV |           -30.5 |\n",
      "|           Entropy |           0.628 |\n",
      "|                KL |         0.00014 |\n",
      "|              Time |             505 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 140 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              36 |\n",
      "|      AverageEpRet |            82.1 |\n",
      "|          StdEpRet |              48 |\n",
      "|          MaxEpRet |             206 |\n",
      "|          MinEpRet |              17 |\n",
      "|             EpLen |            82.1 |\n",
      "|      AverageVVals |            32.9 |\n",
      "|          StdVVals |            13.7 |\n",
      "|          MaxVVals |            50.8 |\n",
      "|          MinVVals |             3.7 |\n",
      "| TotalEnvInteracts |        1.48e+05 |\n",
      "|            LossPi |         -0.0569 |\n",
      "|             LossV |             358 |\n",
      "|       DeltaLossPi |        -0.00126 |\n",
      "|        DeltaLossV |           -62.4 |\n",
      "|           Entropy |           0.622 |\n",
      "|                KL |       -9.26e-05 |\n",
      "|              Time |             519 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 67 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              37 |\n",
      "|      AverageEpRet |            72.8 |\n",
      "|          StdEpRet |            52.2 |\n",
      "|          MaxEpRet |             288 |\n",
      "|          MinEpRet |              18 |\n",
      "|             EpLen |            72.8 |\n",
      "|      AverageVVals |            40.7 |\n",
      "|          StdVVals |            12.8 |\n",
      "|          MaxVVals |            53.3 |\n",
      "|          MinVVals |            5.36 |\n",
      "| TotalEnvInteracts |        1.52e+05 |\n",
      "|            LossPi |          -0.067 |\n",
      "|             LossV |             437 |\n",
      "|       DeltaLossPi |        -0.00148 |\n",
      "|        DeltaLossV |           -73.2 |\n",
      "|           Entropy |           0.631 |\n",
      "|                KL |        0.000288 |\n",
      "|              Time |             529 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 26 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              38 |\n",
      "|      AverageEpRet |            77.9 |\n",
      "|          StdEpRet |            45.9 |\n",
      "|          MaxEpRet |             184 |\n",
      "|          MinEpRet |              12 |\n",
      "|             EpLen |            77.9 |\n",
      "|      AverageVVals |            33.7 |\n",
      "|          StdVVals |            13.3 |\n",
      "|          MaxVVals |            51.2 |\n",
      "|          MinVVals |            0.61 |\n",
      "| TotalEnvInteracts |        1.56e+05 |\n",
      "|            LossPi |         -0.0626 |\n",
      "|             LossV |             326 |\n",
      "|       DeltaLossPi |         -0.0013 |\n",
      "|        DeltaLossV |           -51.8 |\n",
      "|           Entropy |           0.622 |\n",
      "|                KL |        4.29e-05 |\n",
      "|              Time |             537 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 42 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              39 |\n",
      "|      AverageEpRet |            84.2 |\n",
      "|          StdEpRet |            49.3 |\n",
      "|          MaxEpRet |             242 |\n",
      "|          MinEpRet |              23 |\n",
      "|             EpLen |            84.2 |\n",
      "|      AverageVVals |            38.3 |\n",
      "|          StdVVals |            12.8 |\n",
      "|          MaxVVals |            52.8 |\n",
      "|          MinVVals |            3.65 |\n",
      "| TotalEnvInteracts |         1.6e+05 |\n",
      "|            LossPi |         -0.0512 |\n",
      "|             LossV |             335 |\n",
      "|       DeltaLossPi |        -0.00127 |\n",
      "|        DeltaLossV |           -28.4 |\n",
      "|           Entropy |           0.623 |\n",
      "|                KL |        0.000151 |\n",
      "|              Time |             546 |\n",
      "---------------------------------------\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/tf1_save/saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |              40 |\n",
      "|      AverageEpRet |            90.9 |\n",
      "|          StdEpRet |            43.8 |\n",
      "|          MaxEpRet |             196 |\n",
      "|          MinEpRet |              28 |\n",
      "|             EpLen |            90.9 |\n",
      "|      AverageVVals |            36.9 |\n",
      "|          StdVVals |            13.9 |\n",
      "|          MaxVVals |            53.2 |\n",
      "|          MinVVals |            4.09 |\n",
      "| TotalEnvInteracts |        1.64e+05 |\n",
      "|            LossPi |          -0.052 |\n",
      "|             LossV |             318 |\n",
      "|       DeltaLossPi |         -0.0013 |\n",
      "|        DeltaLossV |           -54.1 |\n",
      "|           Entropy |            0.62 |\n",
      "|                KL |        5.37e-05 |\n",
      "|              Time |             556 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 84 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              41 |\n",
      "|      AverageEpRet |            93.2 |\n",
      "|          StdEpRet |            58.7 |\n",
      "|          MaxEpRet |             273 |\n",
      "|          MinEpRet |              12 |\n",
      "|             EpLen |            93.2 |\n",
      "|      AverageVVals |            38.4 |\n",
      "|          StdVVals |            14.6 |\n",
      "|          MaxVVals |            53.2 |\n",
      "|          MinVVals |            3.65 |\n",
      "| TotalEnvInteracts |        1.68e+05 |\n",
      "|            LossPi |         -0.0502 |\n",
      "|             LossV |             412 |\n",
      "|       DeltaLossPi |        -0.00125 |\n",
      "|        DeltaLossV |           -98.4 |\n",
      "|           Entropy |           0.616 |\n",
      "|                KL |       -2.46e-05 |\n",
      "|              Time |             569 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 52 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              42 |\n",
      "|      AverageEpRet |              94 |\n",
      "|          StdEpRet |            60.1 |\n",
      "|          MaxEpRet |             253 |\n",
      "|          MinEpRet |              18 |\n",
      "|             EpLen |              94 |\n",
      "|      AverageVVals |            42.9 |\n",
      "|          StdVVals |            14.6 |\n",
      "|          MaxVVals |            59.2 |\n",
      "|          MinVVals |            2.23 |\n",
      "| TotalEnvInteracts |        1.72e+05 |\n",
      "|            LossPi |         -0.0572 |\n",
      "|             LossV |             382 |\n",
      "|       DeltaLossPi |        -0.00119 |\n",
      "|        DeltaLossV |           -49.9 |\n",
      "|           Entropy |           0.618 |\n",
      "|                KL |        -2.8e-05 |\n",
      "|              Time |             578 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 35 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              43 |\n",
      "|      AverageEpRet |            99.1 |\n",
      "|          StdEpRet |            50.3 |\n",
      "|          MaxEpRet |             236 |\n",
      "|          MinEpRet |              20 |\n",
      "|             EpLen |            99.1 |\n",
      "|      AverageVVals |            40.4 |\n",
      "|          StdVVals |            16.6 |\n",
      "|          MaxVVals |            59.6 |\n",
      "|          MinVVals |            1.41 |\n",
      "| TotalEnvInteracts |        1.76e+05 |\n",
      "|            LossPi |         -0.0578 |\n",
      "|             LossV |             349 |\n",
      "|       DeltaLossPi |        -0.00117 |\n",
      "|        DeltaLossV |             -54 |\n",
      "|           Entropy |           0.613 |\n",
      "|                KL |       -6.33e-05 |\n",
      "|              Time |             586 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 84 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              44 |\n",
      "|      AverageEpRet |             112 |\n",
      "|          StdEpRet |              56 |\n",
      "|          MaxEpRet |             241 |\n",
      "|          MinEpRet |              27 |\n",
      "|             EpLen |             112 |\n",
      "|      AverageVVals |            41.6 |\n",
      "|          StdVVals |              14 |\n",
      "|          MaxVVals |            58.2 |\n",
      "|          MinVVals |            6.26 |\n",
      "| TotalEnvInteracts |         1.8e+05 |\n",
      "|            LossPi |         -0.0524 |\n",
      "|             LossV |             312 |\n",
      "|       DeltaLossPi |        -0.00115 |\n",
      "|        DeltaLossV |           -50.2 |\n",
      "|           Entropy |           0.613 |\n",
      "|                KL |       -8.99e-05 |\n",
      "|              Time |             594 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 58 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              45 |\n",
      "|      AverageEpRet |            96.1 |\n",
      "|          StdEpRet |            56.7 |\n",
      "|          MaxEpRet |             247 |\n",
      "|          MinEpRet |              23 |\n",
      "|             EpLen |            96.1 |\n",
      "|      AverageVVals |            45.5 |\n",
      "|          StdVVals |            16.5 |\n",
      "|          MaxVVals |              62 |\n",
      "|          MinVVals |            6.11 |\n",
      "| TotalEnvInteracts |        1.84e+05 |\n",
      "|            LossPi |         -0.0591 |\n",
      "|             LossV |             316 |\n",
      "|       DeltaLossPi |        -0.00121 |\n",
      "|        DeltaLossV |           -30.6 |\n",
      "|           Entropy |           0.618 |\n",
      "|                KL |        6.11e-05 |\n",
      "|              Time |             606 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 47 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              46 |\n",
      "|      AverageEpRet |            96.4 |\n",
      "|          StdEpRet |            47.4 |\n",
      "|          MaxEpRet |             196 |\n",
      "|          MinEpRet |              21 |\n",
      "|             EpLen |            96.4 |\n",
      "|      AverageVVals |            41.2 |\n",
      "|          StdVVals |            16.1 |\n",
      "|          MaxVVals |            60.3 |\n",
      "|          MinVVals |            3.85 |\n",
      "| TotalEnvInteracts |        1.88e+05 |\n",
      "|            LossPi |         -0.0662 |\n",
      "|             LossV |             304 |\n",
      "|       DeltaLossPi |        -0.00124 |\n",
      "|        DeltaLossV |           -24.4 |\n",
      "|           Entropy |           0.618 |\n",
      "|                KL |        7.18e-05 |\n",
      "|              Time |             622 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 9 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              47 |\n",
      "|      AverageEpRet |             117 |\n",
      "|          StdEpRet |            72.9 |\n",
      "|          MaxEpRet |             326 |\n",
      "|          MinEpRet |              23 |\n",
      "|             EpLen |             117 |\n",
      "|      AverageVVals |            41.4 |\n",
      "|          StdVVals |            14.1 |\n",
      "|          MaxVVals |            57.5 |\n",
      "|          MinVVals |            3.72 |\n",
      "| TotalEnvInteracts |        1.92e+05 |\n",
      "|            LossPi |         -0.0552 |\n",
      "|             LossV |             497 |\n",
      "|       DeltaLossPi |        -0.00119 |\n",
      "|        DeltaLossV |           -89.2 |\n",
      "|           Entropy |           0.611 |\n",
      "|                KL |        9.99e-05 |\n",
      "|              Time |             634 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 79 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              48 |\n",
      "|      AverageEpRet |             103 |\n",
      "|          StdEpRet |            70.2 |\n",
      "|          MaxEpRet |             382 |\n",
      "|          MinEpRet |              17 |\n",
      "|             EpLen |             103 |\n",
      "|      AverageVVals |            47.4 |\n",
      "|          StdVVals |            15.1 |\n",
      "|          MaxVVals |            62.8 |\n",
      "|          MinVVals |            3.97 |\n",
      "| TotalEnvInteracts |        1.96e+05 |\n",
      "|            LossPi |         -0.0682 |\n",
      "|             LossV |             399 |\n",
      "|       DeltaLossPi |        -0.00116 |\n",
      "|        DeltaLossV |           -49.7 |\n",
      "|           Entropy |           0.611 |\n",
      "|                KL |        6.85e-05 |\n",
      "|              Time |             646 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 96 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              49 |\n",
      "|      AverageEpRet |             106 |\n",
      "|          StdEpRet |            62.2 |\n",
      "|          MaxEpRet |             298 |\n",
      "|          MinEpRet |              29 |\n",
      "|             EpLen |             106 |\n",
      "|      AverageVVals |            42.2 |\n",
      "|          StdVVals |            17.7 |\n",
      "|          MaxVVals |            62.8 |\n",
      "|          MinVVals |           -2.71 |\n",
      "| TotalEnvInteracts |           2e+05 |\n",
      "|            LossPi |         -0.0537 |\n",
      "|             LossV |             483 |\n",
      "|       DeltaLossPi |       -0.000915 |\n",
      "|        DeltaLossV |            -101 |\n",
      "|           Entropy |           0.609 |\n",
      "|                KL |        -7.8e-05 |\n",
      "|              Time |             658 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 195 steps.\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/tf1_save/saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |              50 |\n",
      "|      AverageEpRet |             100 |\n",
      "|          StdEpRet |            55.4 |\n",
      "|          MaxEpRet |             239 |\n",
      "|          MinEpRet |              23 |\n",
      "|             EpLen |             100 |\n",
      "|      AverageVVals |            44.9 |\n",
      "|          StdVVals |            13.4 |\n",
      "|          MaxVVals |            61.1 |\n",
      "|          MinVVals |             5.2 |\n",
      "| TotalEnvInteracts |        2.04e+05 |\n",
      "|            LossPi |         -0.0601 |\n",
      "|             LossV |             335 |\n",
      "|       DeltaLossPi |        -0.00107 |\n",
      "|        DeltaLossV |           -35.7 |\n",
      "|           Entropy |           0.608 |\n",
      "|                KL |       -9.03e-07 |\n",
      "|              Time |             669 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 177 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              51 |\n",
      "|      AverageEpRet |             109 |\n",
      "|          StdEpRet |              76 |\n",
      "|          MaxEpRet |             369 |\n",
      "|          MinEpRet |              10 |\n",
      "|             EpLen |             109 |\n",
      "|      AverageVVals |            46.7 |\n",
      "|          StdVVals |              15 |\n",
      "|          MaxVVals |            61.7 |\n",
      "|          MinVVals |            1.89 |\n",
      "| TotalEnvInteracts |        2.08e+05 |\n",
      "|            LossPi |         -0.0583 |\n",
      "|             LossV |             509 |\n",
      "|       DeltaLossPi |       -0.000947 |\n",
      "|        DeltaLossV |           -67.5 |\n",
      "|           Entropy |           0.608 |\n",
      "|                KL |       -5.36e-05 |\n",
      "|              Time |             684 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 82 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              52 |\n",
      "|      AverageEpRet |             115 |\n",
      "|          StdEpRet |            75.7 |\n",
      "|          MaxEpRet |             349 |\n",
      "|          MinEpRet |              24 |\n",
      "|             EpLen |             115 |\n",
      "|      AverageVVals |            47.9 |\n",
      "|          StdVVals |            14.1 |\n",
      "|          MaxVVals |            66.1 |\n",
      "|          MinVVals |            1.49 |\n",
      "| TotalEnvInteracts |        2.12e+05 |\n",
      "|            LossPi |         -0.0641 |\n",
      "|             LossV |             399 |\n",
      "|       DeltaLossPi |       -0.000969 |\n",
      "|        DeltaLossV |           -47.2 |\n",
      "|           Entropy |           0.608 |\n",
      "|                KL |       -6.91e-05 |\n",
      "|              Time |             700 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 12 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              53 |\n",
      "|      AverageEpRet |             111 |\n",
      "|          StdEpRet |            76.7 |\n",
      "|          MaxEpRet |             340 |\n",
      "|          MinEpRet |              23 |\n",
      "|             EpLen |             111 |\n",
      "|      AverageVVals |            42.9 |\n",
      "|          StdVVals |              18 |\n",
      "|          MaxVVals |            67.4 |\n",
      "|          MinVVals |           -2.14 |\n",
      "| TotalEnvInteracts |        2.16e+05 |\n",
      "|            LossPi |         -0.0666 |\n",
      "|             LossV |             469 |\n",
      "|       DeltaLossPi |        -0.00102 |\n",
      "|        DeltaLossV |           -71.7 |\n",
      "|           Entropy |           0.612 |\n",
      "|                KL |        6.55e-05 |\n",
      "|              Time |             712 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 44 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              54 |\n",
      "|      AverageEpRet |             113 |\n",
      "|          StdEpRet |            58.8 |\n",
      "|          MaxEpRet |             244 |\n",
      "|          MinEpRet |              39 |\n",
      "|             EpLen |             113 |\n",
      "|      AverageVVals |            49.7 |\n",
      "|          StdVVals |            16.7 |\n",
      "|          MaxVVals |            66.7 |\n",
      "|          MinVVals |            1.39 |\n",
      "| TotalEnvInteracts |         2.2e+05 |\n",
      "|            LossPi |         -0.0653 |\n",
      "|             LossV |             317 |\n",
      "|       DeltaLossPi |        -0.00123 |\n",
      "|        DeltaLossV |           -41.6 |\n",
      "|           Entropy |           0.608 |\n",
      "|                KL |        8.93e-05 |\n",
      "|              Time |             726 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 3 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              55 |\n",
      "|      AverageEpRet |             114 |\n",
      "|          StdEpRet |            59.2 |\n",
      "|          MaxEpRet |             300 |\n",
      "|          MinEpRet |              26 |\n",
      "|             EpLen |             114 |\n",
      "|      AverageVVals |            44.7 |\n",
      "|          StdVVals |            17.2 |\n",
      "|          MaxVVals |            64.2 |\n",
      "|          MinVVals |            2.58 |\n",
      "| TotalEnvInteracts |        2.24e+05 |\n",
      "|            LossPi |         -0.0631 |\n",
      "|             LossV |             332 |\n",
      "|       DeltaLossPi |         -0.0013 |\n",
      "|        DeltaLossV |           -30.6 |\n",
      "|           Entropy |           0.609 |\n",
      "|                KL |        0.000177 |\n",
      "|              Time |             737 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 25 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              56 |\n",
      "|      AverageEpRet |             132 |\n",
      "|          StdEpRet |            79.7 |\n",
      "|          MaxEpRet |             308 |\n",
      "|          MinEpRet |              31 |\n",
      "|             EpLen |             132 |\n",
      "|      AverageVVals |            49.3 |\n",
      "|          StdVVals |            14.2 |\n",
      "|          MaxVVals |            62.7 |\n",
      "|          MinVVals |            5.99 |\n",
      "| TotalEnvInteracts |        2.28e+05 |\n",
      "|            LossPi |         -0.0599 |\n",
      "|             LossV |             472 |\n",
      "|       DeltaLossPi |       -0.000833 |\n",
      "|        DeltaLossV |           -58.5 |\n",
      "|           Entropy |           0.607 |\n",
      "|                KL |        -6.1e-05 |\n",
      "|              Time |             746 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 46 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              57 |\n",
      "|      AverageEpRet |             136 |\n",
      "|          StdEpRet |            67.3 |\n",
      "|          MaxEpRet |             245 |\n",
      "|          MinEpRet |              41 |\n",
      "|             EpLen |             136 |\n",
      "|      AverageVVals |            45.3 |\n",
      "|          StdVVals |            17.7 |\n",
      "|          MaxVVals |            66.5 |\n",
      "|          MinVVals |            0.16 |\n",
      "| TotalEnvInteracts |        2.32e+05 |\n",
      "|            LossPi |         -0.0526 |\n",
      "|             LossV |             457 |\n",
      "|       DeltaLossPi |       -0.000758 |\n",
      "|        DeltaLossV |            -122 |\n",
      "|           Entropy |           0.603 |\n",
      "|                KL |       -9.21e-05 |\n",
      "|              Time |             755 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 57 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              58 |\n",
      "|      AverageEpRet |             131 |\n",
      "|          StdEpRet |              78 |\n",
      "|          MaxEpRet |             443 |\n",
      "|          MinEpRet |              25 |\n",
      "|             EpLen |             131 |\n",
      "|      AverageVVals |            48.2 |\n",
      "|          StdVVals |            17.4 |\n",
      "|          MaxVVals |            67.7 |\n",
      "|          MinVVals |           -2.49 |\n",
      "| TotalEnvInteracts |        2.36e+05 |\n",
      "|            LossPi |         -0.0587 |\n",
      "|             LossV |             386 |\n",
      "|       DeltaLossPi |         -0.0009 |\n",
      "|        DeltaLossV |           -91.4 |\n",
      "|           Entropy |           0.601 |\n",
      "|                KL |       -2.09e-05 |\n",
      "|              Time |             766 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 14 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              59 |\n",
      "|      AverageEpRet |             142 |\n",
      "|          StdEpRet |            70.2 |\n",
      "|          MaxEpRet |             305 |\n",
      "|          MinEpRet |              20 |\n",
      "|             EpLen |             142 |\n",
      "|      AverageVVals |            51.2 |\n",
      "|          StdVVals |            16.5 |\n",
      "|          MaxVVals |            68.9 |\n",
      "|          MinVVals |            5.84 |\n",
      "| TotalEnvInteracts |         2.4e+05 |\n",
      "|            LossPi |         -0.0415 |\n",
      "|             LossV |             386 |\n",
      "|       DeltaLossPi |       -0.000637 |\n",
      "|        DeltaLossV |           -86.3 |\n",
      "|           Entropy |           0.599 |\n",
      "|                KL |       -0.000127 |\n",
      "|              Time |             779 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 221 steps.\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/tf1_save/saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |              60 |\n",
      "|      AverageEpRet |             118 |\n",
      "|          StdEpRet |            61.9 |\n",
      "|          MaxEpRet |             287 |\n",
      "|          MinEpRet |              31 |\n",
      "|             EpLen |             118 |\n",
      "|      AverageVVals |            52.8 |\n",
      "|          StdVVals |            17.8 |\n",
      "|          MaxVVals |              72 |\n",
      "|          MinVVals |            2.17 |\n",
      "| TotalEnvInteracts |        2.44e+05 |\n",
      "|            LossPi |         -0.0636 |\n",
      "|             LossV |             391 |\n",
      "|       DeltaLossPi |       -0.000815 |\n",
      "|        DeltaLossV |           -82.7 |\n",
      "|           Entropy |           0.606 |\n",
      "|                KL |         3.8e-05 |\n",
      "|              Time |             791 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 193 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              61 |\n",
      "|      AverageEpRet |             146 |\n",
      "|          StdEpRet |            71.1 |\n",
      "|          MaxEpRet |             293 |\n",
      "|          MinEpRet |              19 |\n",
      "|             EpLen |             146 |\n",
      "|      AverageVVals |            45.7 |\n",
      "|          StdVVals |              17 |\n",
      "|          MaxVVals |            67.5 |\n",
      "|          MinVVals |            3.14 |\n",
      "| TotalEnvInteracts |        2.48e+05 |\n",
      "|            LossPi |           -0.06 |\n",
      "|             LossV |             353 |\n",
      "|       DeltaLossPi |       -0.000798 |\n",
      "|        DeltaLossV |            -122 |\n",
      "|           Entropy |             0.6 |\n",
      "|                KL |        3.02e-05 |\n",
      "|              Time |             802 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 132 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              62 |\n",
      "|      AverageEpRet |             121 |\n",
      "|          StdEpRet |            55.4 |\n",
      "|          MaxEpRet |             268 |\n",
      "|          MinEpRet |              22 |\n",
      "|             EpLen |             121 |\n",
      "|      AverageVVals |            56.5 |\n",
      "|          StdVVals |            15.9 |\n",
      "|          MaxVVals |            74.1 |\n",
      "|          MinVVals |            8.42 |\n",
      "| TotalEnvInteracts |        2.52e+05 |\n",
      "|            LossPi |         -0.0412 |\n",
      "|             LossV |             396 |\n",
      "|       DeltaLossPi |        -0.00078 |\n",
      "|        DeltaLossV |            -118 |\n",
      "|           Entropy |             0.6 |\n",
      "|                KL |       -3.09e-06 |\n",
      "|              Time |             816 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 52 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              63 |\n",
      "|      AverageEpRet |             141 |\n",
      "|          StdEpRet |            73.2 |\n",
      "|          MaxEpRet |             346 |\n",
      "|          MinEpRet |              39 |\n",
      "|             EpLen |             141 |\n",
      "|      AverageVVals |            46.7 |\n",
      "|          StdVVals |            17.2 |\n",
      "|          MaxVVals |            68.1 |\n",
      "|          MinVVals |            5.76 |\n",
      "| TotalEnvInteracts |        2.56e+05 |\n",
      "|            LossPi |         -0.0574 |\n",
      "|             LossV |             374 |\n",
      "|       DeltaLossPi |       -0.000697 |\n",
      "|        DeltaLossV |           -64.8 |\n",
      "|           Entropy |           0.601 |\n",
      "|                KL |       -1.38e-05 |\n",
      "|              Time |             832 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 67 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              64 |\n",
      "|      AverageEpRet |             131 |\n",
      "|          StdEpRet |            72.5 |\n",
      "|          MaxEpRet |             325 |\n",
      "|          MinEpRet |              21 |\n",
      "|             EpLen |             131 |\n",
      "|      AverageVVals |            49.5 |\n",
      "|          StdVVals |            18.3 |\n",
      "|          MaxVVals |            71.1 |\n",
      "|          MinVVals |            1.65 |\n",
      "| TotalEnvInteracts |         2.6e+05 |\n",
      "|            LossPi |         -0.0562 |\n",
      "|             LossV |             396 |\n",
      "|       DeltaLossPi |        -0.00067 |\n",
      "|        DeltaLossV |           -53.6 |\n",
      "|           Entropy |           0.602 |\n",
      "|                KL |        7.62e-05 |\n",
      "|              Time |             850 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 179 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              65 |\n",
      "|      AverageEpRet |             142 |\n",
      "|          StdEpRet |            53.8 |\n",
      "|          MaxEpRet |             281 |\n",
      "|          MinEpRet |              59 |\n",
      "|             EpLen |             142 |\n",
      "|      AverageVVals |            52.9 |\n",
      "|          StdVVals |            14.9 |\n",
      "|          MaxVVals |            69.2 |\n",
      "|          MinVVals |             4.1 |\n",
      "| TotalEnvInteracts |        2.64e+05 |\n",
      "|            LossPi |         -0.0579 |\n",
      "|             LossV |             330 |\n",
      "|       DeltaLossPi |       -0.000797 |\n",
      "|        DeltaLossV |           -84.6 |\n",
      "|           Entropy |           0.602 |\n",
      "|                KL |        6.09e-05 |\n",
      "|              Time |             863 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 122 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              66 |\n",
      "|      AverageEpRet |             138 |\n",
      "|          StdEpRet |            81.8 |\n",
      "|          MaxEpRet |             367 |\n",
      "|          MinEpRet |              30 |\n",
      "|             EpLen |             138 |\n",
      "|      AverageVVals |            49.4 |\n",
      "|          StdVVals |            18.2 |\n",
      "|          MaxVVals |            70.6 |\n",
      "|          MinVVals |            2.21 |\n",
      "| TotalEnvInteracts |        2.68e+05 |\n",
      "|            LossPi |         -0.0617 |\n",
      "|             LossV |             322 |\n",
      "|       DeltaLossPi |        -0.00101 |\n",
      "|        DeltaLossV |           -40.6 |\n",
      "|           Entropy |             0.6 |\n",
      "|                KL |        0.000102 |\n",
      "|              Time |             874 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 89 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              67 |\n",
      "|      AverageEpRet |             140 |\n",
      "|          StdEpRet |            65.1 |\n",
      "|          MaxEpRet |             296 |\n",
      "|          MinEpRet |              13 |\n",
      "|             EpLen |             140 |\n",
      "|      AverageVVals |            52.3 |\n",
      "|          StdVVals |            18.6 |\n",
      "|          MaxVVals |            73.2 |\n",
      "|          MinVVals |            5.21 |\n",
      "| TotalEnvInteracts |        2.72e+05 |\n",
      "|            LossPi |         -0.0602 |\n",
      "|             LossV |             314 |\n",
      "|       DeltaLossPi |       -0.000868 |\n",
      "|        DeltaLossV |           -57.8 |\n",
      "|           Entropy |           0.596 |\n",
      "|                KL |       -3.08e-05 |\n",
      "|              Time |             884 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 24 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              68 |\n",
      "|      AverageEpRet |             166 |\n",
      "|          StdEpRet |              69 |\n",
      "|          MaxEpRet |             344 |\n",
      "|          MinEpRet |              77 |\n",
      "|             EpLen |             166 |\n",
      "|      AverageVVals |            49.2 |\n",
      "|          StdVVals |            17.7 |\n",
      "|          MaxVVals |            72.5 |\n",
      "|          MinVVals |            4.22 |\n",
      "| TotalEnvInteracts |        2.76e+05 |\n",
      "|            LossPi |         -0.0515 |\n",
      "|             LossV |             281 |\n",
      "|       DeltaLossPi |       -0.000576 |\n",
      "|        DeltaLossV |           -74.6 |\n",
      "|           Entropy |           0.591 |\n",
      "|                KL |       -1.92e-05 |\n",
      "|              Time |             894 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 83 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              69 |\n",
      "|      AverageEpRet |             151 |\n",
      "|          StdEpRet |            77.3 |\n",
      "|          MaxEpRet |             308 |\n",
      "|          MinEpRet |              34 |\n",
      "|             EpLen |             151 |\n",
      "|      AverageVVals |            56.5 |\n",
      "|          StdVVals |            18.5 |\n",
      "|          MaxVVals |            77.2 |\n",
      "|          MinVVals |            -1.1 |\n",
      "| TotalEnvInteracts |         2.8e+05 |\n",
      "|            LossPi |         -0.0554 |\n",
      "|             LossV |             387 |\n",
      "|       DeltaLossPi |       -0.000959 |\n",
      "|        DeltaLossV |           -58.1 |\n",
      "|           Entropy |           0.602 |\n",
      "|                KL |        0.000199 |\n",
      "|              Time |             904 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 42 steps.\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/tf1_save/saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |              70 |\n",
      "|      AverageEpRet |             147 |\n",
      "|          StdEpRet |            67.8 |\n",
      "|          MaxEpRet |             275 |\n",
      "|          MinEpRet |              37 |\n",
      "|             EpLen |             147 |\n",
      "|      AverageVVals |            51.2 |\n",
      "|          StdVVals |              18 |\n",
      "|          MaxVVals |            74.9 |\n",
      "|          MinVVals |            6.47 |\n",
      "| TotalEnvInteracts |        2.84e+05 |\n",
      "|            LossPi |         -0.0508 |\n",
      "|             LossV |             313 |\n",
      "|       DeltaLossPi |       -0.000725 |\n",
      "|        DeltaLossV |           -95.5 |\n",
      "|           Entropy |           0.592 |\n",
      "|                KL |       -9.38e-05 |\n",
      "|              Time |             913 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 55 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              71 |\n",
      "|      AverageEpRet |             146 |\n",
      "|          StdEpRet |            68.9 |\n",
      "|          MaxEpRet |             369 |\n",
      "|          MinEpRet |              34 |\n",
      "|             EpLen |             146 |\n",
      "|      AverageVVals |            49.4 |\n",
      "|          StdVVals |            20.6 |\n",
      "|          MaxVVals |            75.9 |\n",
      "|          MinVVals |            6.58 |\n",
      "| TotalEnvInteracts |        2.88e+05 |\n",
      "|            LossPi |         -0.0513 |\n",
      "|             LossV |             317 |\n",
      "|       DeltaLossPi |       -0.000614 |\n",
      "|        DeltaLossV |           -81.3 |\n",
      "|           Entropy |           0.601 |\n",
      "|                KL |         9.1e-05 |\n",
      "|              Time |             923 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 77 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              72 |\n",
      "|      AverageEpRet |             163 |\n",
      "|          StdEpRet |            66.3 |\n",
      "|          MaxEpRet |             298 |\n",
      "|          MinEpRet |              28 |\n",
      "|             EpLen |             163 |\n",
      "|      AverageVVals |            57.3 |\n",
      "|          StdVVals |            15.8 |\n",
      "|          MaxVVals |            76.1 |\n",
      "|          MinVVals |            7.59 |\n",
      "| TotalEnvInteracts |        2.92e+05 |\n",
      "|            LossPi |         -0.0439 |\n",
      "|             LossV |             299 |\n",
      "|       DeltaLossPi |       -0.000709 |\n",
      "|        DeltaLossV |           -98.3 |\n",
      "|           Entropy |           0.594 |\n",
      "|                KL |         9.5e-05 |\n",
      "|              Time |             933 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 71 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              73 |\n",
      "|      AverageEpRet |             140 |\n",
      "|          StdEpRet |              63 |\n",
      "|          MaxEpRet |             283 |\n",
      "|          MinEpRet |              46 |\n",
      "|             EpLen |             140 |\n",
      "|      AverageVVals |            52.2 |\n",
      "|          StdVVals |            19.6 |\n",
      "|          MaxVVals |            79.4 |\n",
      "|          MinVVals |            3.11 |\n",
      "| TotalEnvInteracts |        2.96e+05 |\n",
      "|            LossPi |         -0.0501 |\n",
      "|             LossV |             305 |\n",
      "|       DeltaLossPi |       -0.000568 |\n",
      "|        DeltaLossV |           -56.1 |\n",
      "|           Entropy |           0.587 |\n",
      "|                KL |       -7.76e-05 |\n",
      "|              Time |             942 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 87 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              74 |\n",
      "|      AverageEpRet |             170 |\n",
      "|          StdEpRet |            73.1 |\n",
      "|          MaxEpRet |             371 |\n",
      "|          MinEpRet |              60 |\n",
      "|             EpLen |             170 |\n",
      "|      AverageVVals |            51.1 |\n",
      "|          StdVVals |            19.2 |\n",
      "|          MaxVVals |            77.1 |\n",
      "|          MinVVals |            3.79 |\n",
      "| TotalEnvInteracts |           3e+05 |\n",
      "|            LossPi |         -0.0545 |\n",
      "|             LossV |             372 |\n",
      "|       DeltaLossPi |       -0.000604 |\n",
      "|        DeltaLossV |            -123 |\n",
      "|           Entropy |           0.593 |\n",
      "|                KL |        2.07e-05 |\n",
      "|              Time |             952 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 46 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              75 |\n",
      "|      AverageEpRet |             152 |\n",
      "|          StdEpRet |            74.4 |\n",
      "|          MaxEpRet |             339 |\n",
      "|          MinEpRet |              36 |\n",
      "|             EpLen |             152 |\n",
      "|      AverageVVals |            58.5 |\n",
      "|          StdVVals |            18.2 |\n",
      "|          MaxVVals |              80 |\n",
      "|          MinVVals |            5.35 |\n",
      "| TotalEnvInteracts |        3.04e+05 |\n",
      "|            LossPi |         -0.0615 |\n",
      "|             LossV |             391 |\n",
      "|       DeltaLossPi |       -0.000757 |\n",
      "|        DeltaLossV |            -110 |\n",
      "|           Entropy |           0.595 |\n",
      "|                KL |        0.000128 |\n",
      "|              Time |             960 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 184 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              76 |\n",
      "|      AverageEpRet |             153 |\n",
      "|          StdEpRet |            73.8 |\n",
      "|          MaxEpRet |             324 |\n",
      "|          MinEpRet |              12 |\n",
      "|             EpLen |             153 |\n",
      "|      AverageVVals |            47.7 |\n",
      "|          StdVVals |              20 |\n",
      "|          MaxVVals |            72.7 |\n",
      "|          MinVVals |            2.64 |\n",
      "| TotalEnvInteracts |        3.08e+05 |\n",
      "|            LossPi |         -0.0545 |\n",
      "|             LossV |             350 |\n",
      "|       DeltaLossPi |       -0.000768 |\n",
      "|        DeltaLossV |            -118 |\n",
      "|           Entropy |           0.596 |\n",
      "|                KL |        9.48e-05 |\n",
      "|              Time |             970 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 102 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              77 |\n",
      "|      AverageEpRet |             144 |\n",
      "|          StdEpRet |            72.1 |\n",
      "|          MaxEpRet |             287 |\n",
      "|          MinEpRet |              25 |\n",
      "|             EpLen |             144 |\n",
      "|      AverageVVals |            53.2 |\n",
      "|          StdVVals |            18.9 |\n",
      "|          MaxVVals |              77 |\n",
      "|          MinVVals |            2.18 |\n",
      "| TotalEnvInteracts |        3.12e+05 |\n",
      "|            LossPi |         -0.0481 |\n",
      "|             LossV |             368 |\n",
      "|       DeltaLossPi |       -0.000733 |\n",
      "|        DeltaLossV |            -102 |\n",
      "|           Entropy |           0.595 |\n",
      "|                KL |        5.74e-05 |\n",
      "|              Time |             979 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 238 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              78 |\n",
      "|      AverageEpRet |             171 |\n",
      "|          StdEpRet |            52.6 |\n",
      "|          MaxEpRet |             254 |\n",
      "|          MinEpRet |              59 |\n",
      "|             EpLen |             171 |\n",
      "|      AverageVVals |            53.2 |\n",
      "|          StdVVals |            19.9 |\n",
      "|          MaxVVals |            78.4 |\n",
      "|          MinVVals |            4.99 |\n",
      "| TotalEnvInteracts |        3.16e+05 |\n",
      "|            LossPi |         -0.0445 |\n",
      "|             LossV |             257 |\n",
      "|       DeltaLossPi |        -0.00091 |\n",
      "|        DeltaLossV |            -125 |\n",
      "|           Entropy |           0.591 |\n",
      "|                KL |        7.61e-05 |\n",
      "|              Time |             989 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 47 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              79 |\n",
      "|      AverageEpRet |             180 |\n",
      "|          StdEpRet |            78.3 |\n",
      "|          MaxEpRet |             380 |\n",
      "|          MinEpRet |              37 |\n",
      "|             EpLen |             180 |\n",
      "|      AverageVVals |            56.2 |\n",
      "|          StdVVals |            19.3 |\n",
      "|          MaxVVals |            77.4 |\n",
      "|          MinVVals |            6.67 |\n",
      "| TotalEnvInteracts |         3.2e+05 |\n",
      "|            LossPi |          -0.055 |\n",
      "|             LossV |             331 |\n",
      "|       DeltaLossPi |       -0.000878 |\n",
      "|        DeltaLossV |            -107 |\n",
      "|           Entropy |           0.591 |\n",
      "|                KL |        6.16e-05 |\n",
      "|              Time |             997 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 124 steps.\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/tf1_save/saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |              80 |\n",
      "|      AverageEpRet |             176 |\n",
      "|          StdEpRet |              88 |\n",
      "|          MaxEpRet |             355 |\n",
      "|          MinEpRet |              42 |\n",
      "|             EpLen |             176 |\n",
      "|      AverageVVals |            55.3 |\n",
      "|          StdVVals |            21.1 |\n",
      "|          MaxVVals |            81.5 |\n",
      "|          MinVVals |             2.5 |\n",
      "| TotalEnvInteracts |        3.24e+05 |\n",
      "|            LossPi |         -0.0411 |\n",
      "|             LossV |             312 |\n",
      "|       DeltaLossPi |       -0.000595 |\n",
      "|        DeltaLossV |           -48.9 |\n",
      "|           Entropy |            0.59 |\n",
      "|                KL |        0.000137 |\n",
      "|              Time |        1.01e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 106 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              81 |\n",
      "|      AverageEpRet |             177 |\n",
      "|          StdEpRet |            74.5 |\n",
      "|          MaxEpRet |             405 |\n",
      "|          MinEpRet |              86 |\n",
      "|             EpLen |             177 |\n",
      "|      AverageVVals |            57.8 |\n",
      "|          StdVVals |            18.4 |\n",
      "|          MaxVVals |              82 |\n",
      "|          MinVVals |            5.57 |\n",
      "| TotalEnvInteracts |        3.28e+05 |\n",
      "|            LossPi |         -0.0402 |\n",
      "|             LossV |             302 |\n",
      "|       DeltaLossPi |       -0.000732 |\n",
      "|        DeltaLossV |             -92 |\n",
      "|           Entropy |           0.587 |\n",
      "|                KL |        9.77e-05 |\n",
      "|              Time |        1.02e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 5 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              82 |\n",
      "|      AverageEpRet |             154 |\n",
      "|          StdEpRet |            81.4 |\n",
      "|          MaxEpRet |             342 |\n",
      "|          MinEpRet |              26 |\n",
      "|             EpLen |             154 |\n",
      "|      AverageVVals |            57.7 |\n",
      "|          StdVVals |              19 |\n",
      "|          MaxVVals |            80.3 |\n",
      "|          MinVVals |            8.07 |\n",
      "| TotalEnvInteracts |        3.32e+05 |\n",
      "|            LossPi |         -0.0512 |\n",
      "|             LossV |             334 |\n",
      "|       DeltaLossPi |       -0.000547 |\n",
      "|        DeltaLossV |           -80.8 |\n",
      "|           Entropy |           0.591 |\n",
      "|                KL |        8.65e-05 |\n",
      "|              Time |        1.03e+03 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 43 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              83 |\n",
      "|      AverageEpRet |             158 |\n",
      "|          StdEpRet |            58.5 |\n",
      "|          MaxEpRet |             286 |\n",
      "|          MinEpRet |              33 |\n",
      "|             EpLen |             158 |\n",
      "|      AverageVVals |            53.2 |\n",
      "|          StdVVals |            22.8 |\n",
      "|          MaxVVals |            80.5 |\n",
      "|          MinVVals |            2.36 |\n",
      "| TotalEnvInteracts |        3.36e+05 |\n",
      "|            LossPi |         -0.0448 |\n",
      "|             LossV |             263 |\n",
      "|       DeltaLossPi |       -0.000379 |\n",
      "|        DeltaLossV |           -55.6 |\n",
      "|           Entropy |           0.593 |\n",
      "|                KL |        0.000215 |\n",
      "|              Time |        1.04e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 37 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              84 |\n",
      "|      AverageEpRet |             172 |\n",
      "|          StdEpRet |            56.4 |\n",
      "|          MaxEpRet |             252 |\n",
      "|          MinEpRet |              49 |\n",
      "|             EpLen |             172 |\n",
      "|      AverageVVals |            52.6 |\n",
      "|          StdVVals |              18 |\n",
      "|          MaxVVals |              74 |\n",
      "|          MinVVals |            4.51 |\n",
      "| TotalEnvInteracts |         3.4e+05 |\n",
      "|            LossPi |         -0.0521 |\n",
      "|             LossV |             215 |\n",
      "|       DeltaLossPi |        -0.00053 |\n",
      "|        DeltaLossV |           -44.1 |\n",
      "|           Entropy |           0.586 |\n",
      "|                KL |        0.000123 |\n",
      "|              Time |        1.05e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 72 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              85 |\n",
      "|      AverageEpRet |             218 |\n",
      "|          StdEpRet |            98.6 |\n",
      "|          MaxEpRet |             426 |\n",
      "|          MinEpRet |              32 |\n",
      "|             EpLen |             218 |\n",
      "|      AverageVVals |            55.5 |\n",
      "|          StdVVals |            19.3 |\n",
      "|          MaxVVals |            78.9 |\n",
      "|          MinVVals |            7.22 |\n",
      "| TotalEnvInteracts |        3.44e+05 |\n",
      "|            LossPi |         -0.0462 |\n",
      "|             LossV |             336 |\n",
      "|       DeltaLossPi |       -0.000478 |\n",
      "|        DeltaLossV |            -117 |\n",
      "|           Entropy |           0.583 |\n",
      "|                KL |       -1.41e-06 |\n",
      "|              Time |        1.05e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 35 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              86 |\n",
      "|      AverageEpRet |             165 |\n",
      "|          StdEpRet |            72.9 |\n",
      "|          MaxEpRet |             332 |\n",
      "|          MinEpRet |              39 |\n",
      "|             EpLen |             165 |\n",
      "|      AverageVVals |            61.8 |\n",
      "|          StdVVals |            20.8 |\n",
      "|          MaxVVals |            84.9 |\n",
      "|          MinVVals |            3.17 |\n",
      "| TotalEnvInteracts |        3.48e+05 |\n",
      "|            LossPi |         -0.0388 |\n",
      "|             LossV |             351 |\n",
      "|       DeltaLossPi |        -0.00047 |\n",
      "|        DeltaLossV |            -105 |\n",
      "|           Entropy |            0.59 |\n",
      "|                KL |        0.000102 |\n",
      "|              Time |        1.06e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 278 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              87 |\n",
      "|      AverageEpRet |             207 |\n",
      "|          StdEpRet |             100 |\n",
      "|          MaxEpRet |             500 |\n",
      "|          MinEpRet |              93 |\n",
      "|             EpLen |             207 |\n",
      "|      AverageVVals |            57.2 |\n",
      "|          StdVVals |            18.3 |\n",
      "|          MaxVVals |            80.4 |\n",
      "|          MinVVals |            4.76 |\n",
      "| TotalEnvInteracts |        3.52e+05 |\n",
      "|            LossPi |         -0.0507 |\n",
      "|             LossV |             421 |\n",
      "|       DeltaLossPi |       -0.000588 |\n",
      "|        DeltaLossV |             -88 |\n",
      "|           Entropy |           0.581 |\n",
      "|                KL |        2.15e-05 |\n",
      "|              Time |        1.07e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 93 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              88 |\n",
      "|      AverageEpRet |             178 |\n",
      "|          StdEpRet |            73.1 |\n",
      "|          MaxEpRet |             341 |\n",
      "|          MinEpRet |              84 |\n",
      "|             EpLen |             178 |\n",
      "|      AverageVVals |            61.3 |\n",
      "|          StdVVals |              18 |\n",
      "|          MaxVVals |            82.4 |\n",
      "|          MinVVals |           -1.57 |\n",
      "| TotalEnvInteracts |        3.56e+05 |\n",
      "|            LossPi |          -0.046 |\n",
      "|             LossV |             334 |\n",
      "|       DeltaLossPi |       -0.000496 |\n",
      "|        DeltaLossV |           -90.7 |\n",
      "|           Entropy |           0.584 |\n",
      "|                KL |        5.49e-05 |\n",
      "|              Time |        1.08e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 172 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              89 |\n",
      "|      AverageEpRet |             182 |\n",
      "|          StdEpRet |            63.2 |\n",
      "|          MaxEpRet |             272 |\n",
      "|          MinEpRet |              17 |\n",
      "|             EpLen |             182 |\n",
      "|      AverageVVals |            55.4 |\n",
      "|          StdVVals |            20.3 |\n",
      "|          MaxVVals |            81.8 |\n",
      "|          MinVVals |            2.45 |\n",
      "| TotalEnvInteracts |         3.6e+05 |\n",
      "|            LossPi |           -0.05 |\n",
      "|             LossV |             215 |\n",
      "|       DeltaLossPi |        -0.00054 |\n",
      "|        DeltaLossV |           -84.2 |\n",
      "|           Entropy |           0.579 |\n",
      "|                KL |       -6.93e-05 |\n",
      "|              Time |        1.09e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 25 steps.\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/tf1_save/saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |              90 |\n",
      "|      AverageEpRet |             248 |\n",
      "|          StdEpRet |            58.8 |\n",
      "|          MaxEpRet |             351 |\n",
      "|          MinEpRet |             139 |\n",
      "|             EpLen |             248 |\n",
      "|      AverageVVals |            56.7 |\n",
      "|          StdVVals |            21.6 |\n",
      "|          MaxVVals |            83.7 |\n",
      "|          MinVVals |            6.42 |\n",
      "| TotalEnvInteracts |        3.64e+05 |\n",
      "|            LossPi |         -0.0283 |\n",
      "|             LossV |             230 |\n",
      "|       DeltaLossPi |       -0.000366 |\n",
      "|        DeltaLossV |            -130 |\n",
      "|           Entropy |           0.576 |\n",
      "|                KL |       -7.46e-05 |\n",
      "|              Time |         1.1e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 54 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              91 |\n",
      "|      AverageEpRet |             208 |\n",
      "|          StdEpRet |            84.3 |\n",
      "|          MaxEpRet |             416 |\n",
      "|          MinEpRet |              69 |\n",
      "|             EpLen |             208 |\n",
      "|      AverageVVals |            67.5 |\n",
      "|          StdVVals |            19.3 |\n",
      "|          MaxVVals |            89.3 |\n",
      "|          MinVVals |            5.02 |\n",
      "| TotalEnvInteracts |        3.68e+05 |\n",
      "|            LossPi |         -0.0302 |\n",
      "|             LossV |             346 |\n",
      "|       DeltaLossPi |       -0.000493 |\n",
      "|        DeltaLossV |            -111 |\n",
      "|           Entropy |           0.581 |\n",
      "|                KL |        4.57e-05 |\n",
      "|              Time |         1.1e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 56 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              92 |\n",
      "|      AverageEpRet |             219 |\n",
      "|          StdEpRet |             107 |\n",
      "|          MaxEpRet |             493 |\n",
      "|          MinEpRet |              49 |\n",
      "|             EpLen |             219 |\n",
      "|      AverageVVals |            60.2 |\n",
      "|          StdVVals |            22.2 |\n",
      "|          MaxVVals |            88.6 |\n",
      "|          MinVVals |            7.21 |\n",
      "| TotalEnvInteracts |        3.72e+05 |\n",
      "|            LossPi |         -0.0379 |\n",
      "|             LossV |             274 |\n",
      "|       DeltaLossPi |       -0.000561 |\n",
      "|        DeltaLossV |             -76 |\n",
      "|           Entropy |            0.58 |\n",
      "|                KL |        6.97e-05 |\n",
      "|              Time |        1.11e+03 |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: trajectory cut off by epoch at 330 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              93 |\n",
      "|      AverageEpRet |             262 |\n",
      "|          StdEpRet |              83 |\n",
      "|          MaxEpRet |             455 |\n",
      "|          MinEpRet |             143 |\n",
      "|             EpLen |             262 |\n",
      "|      AverageVVals |            63.8 |\n",
      "|          StdVVals |              20 |\n",
      "|          MaxVVals |            88.6 |\n",
      "|          MinVVals |           0.358 |\n",
      "| TotalEnvInteracts |        3.76e+05 |\n",
      "|            LossPi |         -0.0306 |\n",
      "|             LossV |             334 |\n",
      "|       DeltaLossPi |       -0.000234 |\n",
      "|        DeltaLossV |            -123 |\n",
      "|           Entropy |           0.575 |\n",
      "|                KL |        5.02e-06 |\n",
      "|              Time |        1.12e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 47 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              94 |\n",
      "|      AverageEpRet |             180 |\n",
      "|          StdEpRet |            98.6 |\n",
      "|          MaxEpRet |             387 |\n",
      "|          MinEpRet |              20 |\n",
      "|             EpLen |             180 |\n",
      "|      AverageVVals |            65.5 |\n",
      "|          StdVVals |            22.5 |\n",
      "|          MaxVVals |            91.1 |\n",
      "|          MinVVals |            1.03 |\n",
      "| TotalEnvInteracts |         3.8e+05 |\n",
      "|            LossPi |         -0.0471 |\n",
      "|             LossV |             450 |\n",
      "|       DeltaLossPi |       -0.000474 |\n",
      "|        DeltaLossV |            -225 |\n",
      "|           Entropy |           0.582 |\n",
      "|                KL |        5.89e-05 |\n",
      "|              Time |        1.14e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 345 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              95 |\n",
      "|      AverageEpRet |             228 |\n",
      "|          StdEpRet |            97.7 |\n",
      "|          MaxEpRet |             500 |\n",
      "|          MinEpRet |             104 |\n",
      "|             EpLen |             228 |\n",
      "|      AverageVVals |            59.9 |\n",
      "|          StdVVals |            21.1 |\n",
      "|          MaxVVals |            89.1 |\n",
      "|          MinVVals |           -2.92 |\n",
      "| TotalEnvInteracts |        3.84e+05 |\n",
      "|            LossPi |         -0.0333 |\n",
      "|             LossV |             388 |\n",
      "|       DeltaLossPi |       -0.000383 |\n",
      "|        DeltaLossV |            -177 |\n",
      "|           Entropy |           0.573 |\n",
      "|                KL |       -2.01e-05 |\n",
      "|              Time |        1.15e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 29 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              96 |\n",
      "|      AverageEpRet |             209 |\n",
      "|          StdEpRet |            80.1 |\n",
      "|          MaxEpRet |             405 |\n",
      "|          MinEpRet |              95 |\n",
      "|             EpLen |             209 |\n",
      "|      AverageVVals |            64.9 |\n",
      "|          StdVVals |            20.5 |\n",
      "|          MaxVVals |            86.7 |\n",
      "|          MinVVals |            7.33 |\n",
      "| TotalEnvInteracts |        3.88e+05 |\n",
      "|            LossPi |         -0.0417 |\n",
      "|             LossV |             294 |\n",
      "|       DeltaLossPi |       -0.000409 |\n",
      "|        DeltaLossV |            -109 |\n",
      "|           Entropy |           0.575 |\n",
      "|                KL |       -2.26e-05 |\n",
      "|              Time |        1.16e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 132 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              97 |\n",
      "|      AverageEpRet |             228 |\n",
      "|          StdEpRet |             128 |\n",
      "|          MaxEpRet |             500 |\n",
      "|          MinEpRet |              34 |\n",
      "|             EpLen |             228 |\n",
      "|      AverageVVals |            62.9 |\n",
      "|          StdVVals |            20.8 |\n",
      "|          MaxVVals |            85.4 |\n",
      "|          MinVVals |            5.39 |\n",
      "| TotalEnvInteracts |        3.92e+05 |\n",
      "|            LossPi |         -0.0446 |\n",
      "|             LossV |             359 |\n",
      "|       DeltaLossPi |        -0.00041 |\n",
      "|        DeltaLossV |            -111 |\n",
      "|           Entropy |            0.58 |\n",
      "|                KL |           7e-05 |\n",
      "|              Time |        1.17e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 220 steps.\n",
      "---------------------------------------\n",
      "|             Epoch |              98 |\n",
      "|      AverageEpRet |             180 |\n",
      "|          StdEpRet |            58.6 |\n",
      "|          MaxEpRet |             339 |\n",
      "|          MinEpRet |             104 |\n",
      "|             EpLen |             180 |\n",
      "|      AverageVVals |            62.7 |\n",
      "|          StdVVals |            21.5 |\n",
      "|          MaxVVals |            87.4 |\n",
      "|          MinVVals |            2.68 |\n",
      "| TotalEnvInteracts |        3.96e+05 |\n",
      "|            LossPi |         -0.0482 |\n",
      "|             LossV |             244 |\n",
      "|       DeltaLossPi |       -0.000527 |\n",
      "|        DeltaLossV |           -84.9 |\n",
      "|           Entropy |           0.574 |\n",
      "|                KL |         7.7e-05 |\n",
      "|              Time |        1.18e+03 |\n",
      "---------------------------------------\n",
      "Warning: trajectory cut off by epoch at 164 steps.\n",
      "\u001b[31;1mWarning: could not pickle state_dict.\u001b[0m\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: /Users/seanlin/Desktop/MehtaKnights-189/prob2/data/vpg/vpg_s0/tf1_save/saved_model.pb\n",
      "---------------------------------------\n",
      "|             Epoch |              99 |\n",
      "|      AverageEpRet |             183 |\n",
      "|          StdEpRet |            95.5 |\n",
      "|          MaxEpRet |             454 |\n",
      "|          MinEpRet |              44 |\n",
      "|             EpLen |             183 |\n",
      "|      AverageVVals |            55.8 |\n",
      "|          StdVVals |            20.2 |\n",
      "|          MaxVVals |            83.3 |\n",
      "|          MinVVals |            4.01 |\n",
      "| TotalEnvInteracts |           4e+05 |\n",
      "|            LossPi |         -0.0478 |\n",
      "|             LossV |             295 |\n",
      "|       DeltaLossPi |       -0.000761 |\n",
      "|        DeltaLossV |           -72.3 |\n",
      "|           Entropy |           0.576 |\n",
      "|                KL |        0.000197 |\n",
      "|              Time |        1.19e+03 |\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "env = 'CartPole-v1'\n",
    "\n",
    "### SOLUTION ###\n",
    "nn_units = 64\n",
    "depth = 2\n",
    "steps = 4000\n",
    "epochs = 100\n",
    "### END ###\n",
    "gamma = 0.99\n",
    "seed = 0\n",
    "# parser.add_argument('--cpu', type=int, default=2)\n",
    "exp_name = 'vpg'\n",
    "\n",
    "# Reset the default graph to prevent errors on multiple runs of Vanilla Policy Gradient\n",
    "tf.reset_default_graph()\n",
    "logger_kwargs = setup_logger_kwargs(exp_name, seed)\n",
    "\n",
    "vpg.run(lambda : gym.make(env), actor_critic=core.mlp_actor_critic,\n",
    "    ac_kwargs=dict(policy=mlp_categorical_policy, nn_sizes=[nn_units]*depth), gamma=gamma, \n",
    "    seed=seed, steps_per_epoch=steps, epochs=epochs,\n",
    "    logger_kwargs=logger_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You're done! Isn't it cool what reinforcement learning can do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spinningup",
   "language": "python",
   "name": "spinningup"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
